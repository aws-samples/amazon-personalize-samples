{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisations des objectifs\n",
    "\n",
    "Ce bloc-notes démontre un cas d'utilisation pour l'optimisation des objectifs d'Amazon Personalize. Souvent, d'autres facteurs influencent les recommandations et l'optimisation des objectifs peut être utilisée pour fournir des données supplémentaires pour gérer le modèle.\n",
    "\n",
    "Cet exemple suppose que nous fournissons des recommandations pour un service d'abonnement de vidéo à la demande (VOD) en continu. Le service permet aux utilisateurs un accès illimité au catalogue vidéo, mais les titres disponibles dans leur catalogue sont soumis à des conditions de licence différentes selon l'accord avec le propriétaire du contenu. En fournissant des recommandations qui pondèrent le contenu dont les coûts de licence sont les plus bas, le service de streaming peut réduire les coûts de licence tout en gardant les clients satisfaits.\n",
    "\n",
    "Encore une fois, les données proviennent du projet [MovieLens](https://movielens.org/). Vous pouvez obtenir plus d'informations sur les données et les utilisations potentielles en effectuant une recherche sur Internet pendant l'une des périodes d'attente dans les cellules ci-dessous. Vous ajouterez aux données de MovieLens un champ supplémentaire pour les redevances et générerez les données qui fourniront les coûts des redevances au jeu de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment utiliser le bloc-notes\n",
    "\n",
    "Le code est décomposé en cellules comme celle ci-dessous. Il y a un bouton `Run` triangulaire en haut de cette page qui vous permet d'exécuter chaque cellule et de passer à la suivante, ou vous pouvez appuyer sur `Shift` + `Enter` lorsque vous êtes dans la cellule pour l'exécuter et passer à la suivante.\n",
    "\n",
    "Lorsqu'une cellule est en cours d'exécution, vous remarquerez une ligne sur le coté affichant une `*` pendant que la cellule est opérationnelle ou elle se mettra à jour sous forme de nombre pour indiquer la dernière cellule qui a terminé l'exécution après avoir achevé l'exécution de tous les codes dans une cellule.\n",
    "\n",
    "\n",
    "Suivez les instructions ci-dessous et exécutez les cellules pour démarrer avec l'optimisation des objectifs d'Amazon Personalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations \n",
    "\n",
    "Python est livré avec une large gamme de bibliothèques. Nous devons les importer, ainsi que celles qui sont installées pour nous aider, comme [boto3](https://aws.amazon.com/sdk-for-python/) (AWS SDK pour python) et [Pandas](https://pandas.pydata.org/)/[Numpy](https://numpy.org/), qui sont des outils essentiels pour la science des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "!conda install -y -c conda-forge unzip\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, vous devez vérifier que votre environnement peut communiquer avec Amazon Personalize. Les lignes ci-dessous servent à cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurer les données\n",
    "\n",
    "Les données sont importées dans Amazon Personalize par le biais d'Amazon S3. Nous allons spécifier ci-dessous les noms de fichiers que vous utilisez pour écrire les fichiers localement avant de les charger sur S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"movie-lens-100k.csv\"\n",
    "items_filename = \"movie-lens-items.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Télécharger, préparer et charger les données d'entraînement\n",
    "\n",
    "Actuellement, vous n'avez pas encore chargé les données de MovieLens localement pour les examiner. Exécutez les lignes ci-dessous pour télécharger la dernière copie et l'examiner rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Télécharger et explorer le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparer et charger les données\n",
    "\n",
    "Le code ci-dessous charge les informations sur le film à partir du téléchargement de MovieLens. Il fournit des informations sur le titre, la date de sortie, le lien IMDB et la liste des colonnes indiquant les genres qui s'appliquent au titre.\n",
    "\n",
    "Il n'y a pas de champ de redevance puisque l'atelier génère une redevance fictive, ce qui sera fait à l'étape suivante.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|',encoding='latin-1', names=['ITEM_ID', 'TITLE', 'RELEASE_DATE', 'VIDEO_RELEASE_DATE', 'IMDB_URL', 'MISC', 'ACTION_GENRE', 'ADVENTURE_GENRE', 'ANIMATION_GENRE', 'CHILDRENS_GENRE','COMEDY_GENRE', 'CRIME_GENRE', 'DOCUMENTARY_GENRE','DRAMA_GENRE','FANTASY_GENRE', 'FILMNOIR_GENRE','HORROR_GENRE', 'MUSICAL_GENRE','MYSTERY_GENRE', 'ROMANCE_GENRE', 'SCIFI_GENRE', 'THRILLER_GENRE', 'WAR_GENRE', 'WESTERN_GENRE'     ])\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter les données de redevance et les genres\n",
    "Nous attribuons une valeur au champ REDEVANCE avec une distribution régulière des valeurs 0.0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.05, 0.10. Cela signifie que la plupart des films ont une redevance relativement faible ou nulle et qu'un petit nombre de films ont une redevance plus élevée. \n",
    "\n",
    "Remarquez sur le graphique à barres ci-dessous la distribution régulière des titres avec chaque valeur de redevance.\n",
    "\n",
    "Le résultat du champ GENRE de MovieLens ci-dessus est catégorique, chaque colonne indiquant si le titre appartient au genre, mais les articles chargés dans la personnalisation peuvent accepter des tableaux. Quelques codes de pandas pour rassembler les genres dans une colonne délimitée par des pipes listant tous les genres.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "royaltyvalues = [0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.05, 0.10]\n",
    "items.loc[:,'ROYALTY'] = items['ITEM_ID'].map(lambda x: royaltyvalues[x%8])\n",
    "\n",
    "items.loc[:,'GENRE']='' \n",
    "\n",
    "for col_name in items.columns:\n",
    "    if col_name.endswith('_GENRE'):\n",
    "        items.loc[items[col_name]==1,'GENRE']= items['GENRE']+'|'+ col_name[:-6]\n",
    "\n",
    "items = items[['ITEM_ID', 'TITLE','ROYALTY', 'GENRE']]\n",
    "items.loc[:,'GENRE'] = items['GENRE'].str[1:]\n",
    "\n",
    "\n",
    "items.loc[:,'ROYALTY'].value_counts().plot.bar()\n",
    "items.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réglez la valeur de la redevance sur un nombre négatif.\n",
    "\n",
    "L'optimisation d'objectif optimisera les valeurs les plus élevées d'un champ. Dans ce cas, nous devons équilibrer la pertinence du film par rapport aux frais de redevance qui seront encourus par le service de streaming.\n",
    "\n",
    "Les films dont les redevances sont les plus faibles doivent avoir les valeurs numériques les plus élevées afin de les stimuler. Dans ce cas, nous allons convertir les redevances en un nombre négatif. Pour ce faire, il faut multiplier -1 par la valeur absolue de la redevance.\n",
    "\n",
    "Remarque : La valeur absolue est utilisée afin de pouvoir exécuter cette cellule deux fois avec les mêmes résultats, ce qui est utile dans un environnement d'atelier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.loc[:,'ROYALTY'] = -1 * abs(items['ROYALTY'])\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurer un compartiment S3 et un rôle IAM <a class=\"anchor\" id=\"bucket_role\"></a>\n",
    "Pour l'instant, nous avons téléchargé, manipulé et enregistré les données sur l'instance Amazon EBS associée à l'instance qui exécute ce bloc-notes Jupyter. Toutefois, Amazon Personalize aura besoin d'un compartiment S3 pour servir de source à vos données, ainsi que de rôles IAM pour accéder à ce compartiment. Mettons tout cela en place.\n",
    "\n",
    "Utilisez les métadonnées stockées sur l'instance sous-jacente de ce bloc-notes Amazon SageMaker pour déterminer la région dans laquelle il fonctionne. Si vous utilisez un bloc-notes Jupyter en dehors d'Amazon SageMaker, définissez simplement la région sous forme de chaîne comme suit. Le compartiment Amazon S3 doit se trouver dans la même région que les ressources Amazon Personalize que nous avons créées jusqu'à présent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    notebook_data = json.load(notebook_info)\n",
    "    resource_arn = notebook_data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les noms des compartiments Amazon S3 sont uniques au niveau mondial. Pour créer un nom de compartiment unique, le code ci-dessous ajoutera la chaîne de caractères `personalize-objective-optimization-` à votre numéro de compte AWS. Puis il crée un compartiment avec ce nom dans la région découverte dans la cellule précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "bucket_name = \"personalize-objective-optimization-\"+   suffix        # replace with the name of your S3 bucket\n",
    "print(bucket_name)\n",
    "if region != \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "else:\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les données vers S3\n",
    "\n",
    "Maintenant que votre compartiment Amazon S3 a été créé, chargez le fichier CSV de nos données d'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items[['ITEM_ID', 'TITLE', 'GENRE', 'ROYALTY']]\n",
    "items_dataset = items[['ITEM_ID','ROYALTY', 'GENRE']]\n",
    "\n",
    "items_dataset.to_csv(items_filename, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(items_filename).upload_file(items_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définir la politique du compartiment S3\n",
    "Amazon Personalize doit pouvoir lire le contenu de votre compartiment S3. Il faut donc ajouter une politique de compartiment qui l'autorise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer le schéma de l'article du titre du film\n",
    "Nous aurons besoin de deux schémas, un pour les titres de films, qui sera de type article, et un second qui définira la structure des interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ROYALTY\",\n",
    "            \"type\": \"float\"\n",
    "        },        {\n",
    "            \"name\": \"GENRE\",\n",
    "            \"type\": [\n",
    "                \"null\",\n",
    "                \"string\"\n",
    "              ],\n",
    "            \"categorical\": True\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_item_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-objective-optmization-item-schema\"+suffix,\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "item_schema_arn = create_item_schema_response['schemaArn']\n",
    "print(json.dumps(create_item_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de ce point, nous suivrons le même processus que pour la [première campagne](https://github.com/aws-samples/amazon-personalize-samples/blob/master/getting_started/notebooks/1.Building_Your_First_Campaign.ipynb), en chargeant les interactions. Nous ne devons inclure que les interactions ayant au moins une note de trois, et nous ne voulons pas recommander des films que les spectateurs n'aimeront pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['RATING'] > 3]                # Keep only movies rated higher than 3 out of 5.\n",
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "data.to_csv(filename, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un schéma d'interaction\n",
    "\n",
    "L'un des principaux articles permettant à Personalize de comprendre vos données provient du schéma défini ci-dessous. Cette configuration indique au service comment traiter les données fournies par votre fichier CSV. Notez que les colonnes et les types s'alignent sur les articles présents dans le fichier que vous avez créé ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-objective-optmization-schema\"+suffix,\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer et attendre un groupe de jeux de données\n",
    "\n",
    "Le groupe le plus important dans Personalize est le groupe de jeu de données, qui permet d'isoler vos données, vos traceurs d'événements, vos solutions et vos campagnes. Regroupement de choses qui partagent un ensemble commun de données. N'hésitez pas à modifier le nom ci-dessous si vous le souhaitez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un groupe de jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-objective-optmization-demo-\"+suffix\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que le groupe de jeu de données ait le statut ACTIF\n",
    "\n",
    "Avant de pouvoir utiliser le groupe de jeu de données dans les articles ci-dessous, il doit être actif; exécutez la cellule ci-dessous et attendez qu'il soit actif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un jeu de données\n",
    "\n",
    "Après le groupe, la prochaine chose à créer est les jeux de données réels. Dans cet exemple, nous allons créer un jeu de données pour les interactions et un autre pour les données des articles. Exécutez les cellules ci-dessous pour le créer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_type, schema_arn, name):\n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = schema_arn\n",
    "    )\n",
    "    dataset_arn = create_dataset_response['datasetArn']\n",
    "\n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        describe_dataset_response = personalize.describe_dataset(\n",
    "            datasetArn = dataset_arn\n",
    "        )\n",
    "        status = describe_dataset_response[\"dataset\"][\"status\"]\n",
    "        print(\"Dataset: {} {}\".format(name, status))\n",
    "\n",
    "        if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "            break\n",
    "\n",
    "        time.sleep(10)\n",
    "    return dataset_arn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_dataset_arn = create_dataset(\"INTERACTIONS\", schema_arn, 'personalize-objective-optmization-interactions-'+suffix)\n",
    "\n",
    "\n",
    "print('interaction_dataset_arn: ' + interaction_dataset_arn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dataset_arn = create_dataset(\"ITEMS\", item_schema_arn, 'personalize-objective-optmization-items-'+suffix)\n",
    "print('item_dataset_arn: ' + item_dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un rôle Personalize\n",
    "\n",
    "De plus, Amazon Personalize doit pouvoir assumer des rôles dans AWS, afin d'avoir les autorisations d'exécuter certaines tâches. Les lignes ci-dessous les accordent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRoleDemo\"+suffix\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les données\n",
    "\n",
    "Vous avez précédemment créé le groupe de jeu de données et le jeu de données pour héberger vos informations. Vous allez maintenant exécuter une tâche d'importation qui chargera les données de S3 dans Amazon Personalize pour les utiliser dans la création de votre modèle. Nous allons charger plusieurs importations. La fonction ci-dessous sera donc utilisée pour démarrer la tâche d'importation, puis surveiller l'achèvement de la tâche d'importation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une tâche d'importation de jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_import_job(dataset_arn, dataLocation, name):\n",
    "    create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "        jobName = name,\n",
    "        datasetArn = dataset_arn,\n",
    "        dataSource = {\n",
    "            \"dataLocation\": dataLocation\n",
    "        },\n",
    "        roleArn = role_arn\n",
    "    )\n",
    "\n",
    "    dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "    \n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "            datasetImportJobArn = dataset_import_job_arn\n",
    "        )\n",
    "        status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "        print(\"DatasetImportJob: {} {}\".format(name, status))\n",
    "\n",
    "        if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "            break\n",
    "\n",
    "        time.sleep(60)\n",
    "    return dataset_import_job_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger les interactions\n",
    "La tâche d'importation ci-dessous chargera le jeu de données d'interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_import_job_arn = create_dataset_import_job(interaction_dataset_arn, \"s3://{}/{}\".format(bucket_name, filename), \"personalize-objective-optimization-interaction-\"+suffix)\n",
    "print('dataset_import_job_arn: ' + dataset_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargez les titres de films dans le jeu de données des articles\n",
    "\n",
    "La tâche d'importation peut durer un certain temps ; veuillez patienter jusqu'à ce que vous voyiez qu'elle est active ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dataset_import_job_arn = create_dataset_import_job(item_dataset_arn, \"s3://{}/{}\".format(bucket_name, items_filename), \"personalize-objective-optimization-item-\"+suffix)\n",
    "print('item_dataset_import_job_arn: ' + item_dataset_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer la solution et la version\n",
    "\n",
    "Dans Amazon Personalize, un modèle entraîné est appelé Solution. Chaque Solution peut avoir plusieurs versions spécifiques qui se rapportent à un volume de données donné lorsque le modèle a été formé.\n",
    "\n",
    "Pour commencer, nous allons énumérer toutes les recettes qui sont prises en charge. Une recette est un algorithme qui n'a pas encore été entraîné sur vos données. Après l'énumération, vous en choisirez une et l'utiliserez pour créer votre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélectionner une recette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personnalisation de l'utilisateur\n",
    "La recette [Personnalisation utilisateur](https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-new-item-USER_PERSONALIZATION.html) (aws-user-personalization) est optimisée pour tous les scénarios de recommandation USER_PERSONALIZATION. Lorsque vous recommandez des articles, elle utilise l'exploration automatique des articles.\n",
    "\n",
    "Avec l'exploration automatique, Amazon Personalize teste automatiquement les différentes recommandations d'articles, découvre comment les utilisateurs interagissent avec ces articles recommandés et stimule les recommandations pour les articles qui favorisent un meilleur engagement et une meilleure conversion. Cela améliore la découverte des articles et l'engagement lorsque vous disposez d'un catalogue qui évolue rapidement, ou lorsque de nouveaux articles, tels que des articles d'actualité ou des promotions, sont plus pertinents pour les utilisateurs lorsqu'ils sont frais.\n",
    "\n",
    "Vous pouvez équilibrer le niveau d'exploration (où les articles présentant moins de données d'interaction ou de pertinence sont recommandés plus fréquemment) et le niveau d'exploitation (où les recommandations sont basées sur ce que nous savons ou sur la pertinence). Amazon Personalize ajuste automatiquement les recommandations futures en fonction des retours implicites des utilisateurs.\n",
    "\n",
    "Tout d'abord, sélectionnez la recette en trouvant l'ARN dans la liste des recettes ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\" # aws-user-personalization selected for demo purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer et attendre la solution\n",
    "\n",
    "Vous créez d'abord la solution avec l'API, puis vous créez une version. L'entraînement de votre modèle pour créer votre version de la solution prendra plusieurs minutes. Une fois qu'il a commencé et que vous voyez les notifications en cours, c'est le moment de faire une pause, de prendre un café, etc.\n",
    "\n",
    "La fonction accepte le paramètre de sensibilité de l'objectif, qui peut être OFF, LOW, MED ou HIGH (INACTIF, FAIBLE, MOYEN ou ÉLEVÉ). Cela permettra d'ajuster la pondération qui introduit l'impact de l'objectif dans le modèle.\n",
    "\n",
    "La fonction crée la solution et la version initiale de la solution pour cette solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_solution(name, objectiveSensitivity):\n",
    "    create_solution_response = personalize.create_solution(\n",
    "        name = name,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        recipeArn = recipe_arn,\n",
    "        solutionConfig = {\n",
    "            \"optimizationObjective\": {\n",
    "                \"itemAttribute\": \"ROYALTY\",\n",
    "                \"objectiveSensitivity\":objectiveSensitivity\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    solution_arn = create_solution_response['solutionArn']\n",
    "    \n",
    "    print('solutionArn:' + solution_arn)\n",
    "\n",
    "    create_solution_version_response = personalize.create_solution_version(\n",
    "        solutionArn = solution_arn\n",
    "    )\n",
    "\n",
    "    solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "    print('solution_version_arn: ' + solution_version_arn)\n",
    "\n",
    "    return {\n",
    "        \"solution_arn\": solution_arn,\n",
    "        \"solution_version_arn\": solution_version_arn\n",
    "    }\n",
    "    \n",
    "def waitForSolutionVersion(solution_version_arn):\n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        describe_solution_version_response = personalize.describe_solution_version(\n",
    "            solutionVersionArn = solution_version_arn\n",
    "        )\n",
    "        status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "        print(\"SolutionVersion: {} {}\".format(solution_version_arn, status))\n",
    "\n",
    "        if status == \"ACTIVE\" or status == \"CREATE FAILED\"  or status == \"CREATE STOPPING\":\n",
    "            break\n",
    "\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer les versions de la solution\n",
    "Créer trois solutions différentes, l'une avec l'optimisation des objectifs désactivée, l'une avec un réglage faible et l'autre avec un réglage élevé. Cela lancera trois solutions parallèlement et l'étape suivante attendra qu'elles soient terminées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_solution = create_solution('movie-recommendation-low-royalties-'+suffix, 'HIGH')\n",
    "low_solution = create_solution('movie-recommendation-medium-royalties-'+suffix, 'LOW')\n",
    "no_objective_optimization_solution = create_solution('movie-recommendation-max-relevance-'+suffix, 'OFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que les versions de la solution aient le statut ACTIF\n",
    "\n",
    "Cela prendra environ 40 à 50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitForSolutionVersion(low_solution['solution_version_arn'])\n",
    "waitForSolutionVersion(no_objective_optimization_solution['solution_version_arn'])\n",
    "waitForSolutionVersion(high_solution['solution_version_arn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenir des métriques des versions de la solution\n",
    "\n",
    "Maintenant que votre solution et sa version sont en place, vous pouvez obtenir les métriques qui vous permettront de juger de ses performances. Ces métriques ne sont pas particulièrement bonnes, car il s'agit d'un jeu de données de démonstration. Cependant, vous vous devriez constater des améliorations avec des jeux de données plus grands et plus complexes.\n",
    "\n",
    "Vous pouvez constater des différences dans la qualité du modèle en fonction de l'impact des optimisations des objectifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution_metrics(solutions):\n",
    "    metricdata = { \"name\": []}\n",
    "    \n",
    "    for key in solutions:\n",
    "        solution = solutions[key]\n",
    "        \n",
    "        metricdata[\"name\"].append(key)\n",
    "        \n",
    "        get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "            solutionVersionArn = solution['solution_version_arn']\n",
    "        )\n",
    "\n",
    "        for metricname in get_solution_metrics_response['metrics']:\n",
    "            if not metricname in metricdata:\n",
    "                metricdata[metricname] = []\n",
    "                \n",
    "            metricdata[metricname].append( get_solution_metrics_response['metrics'][metricname])\n",
    "            \n",
    "        # print(json.dumps(get_solution_metrics_response, indent=2))\n",
    "    return pd.DataFrame.from_dict(metricdata);\n",
    "\n",
    "metrics = get_solution_metrics({\n",
    "    \"no-optimization\": no_objective_optimization_solution,\n",
    "    \"low-optimization\": low_solution,\n",
    "    \"high-optimization\": high_solution,\n",
    "})\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous recommandons de lire [la documentation](https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html) pour comprendre les métriques, mais nous avons également copié des parties de la documentation ci-dessous pour plus de commodité.\n",
    "\n",
    "Vous devez comprendre les termes suivants à propos de l'évaluation dans Personalize :\n",
    "\n",
    "- *Relevant recommendation* est une recommandation qui correspond à une valeur dans les données de test pour un utilisateur particulier.\n",
    "- *Rank* fait référence à la position d'un article recommandé dans la liste des recommandations. La position 1 (haut de la liste) est présumée être la plus pertinente pour l'utilisateur.\n",
    "- *Query* fait référence à l'équivalent interne d'un appel GetRecommendations.\n",
    "\n",
    "Les métriques fournies par Personalize sont les suivantes :\n",
    "\n",
    "- coverage : La proportion d'articles uniques recommandés à partir de toutes les requêtes sur le nombre total d'articles uniques dans les données de formation (comprend à la fois les jeux de données d'articles et d'interactions).\n",
    "- mean_reciprocal_rank_at_25 : La [moyenne des rangs réciproques](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) de la première recommandation pertinente parmi les 25 premières recommandations pour toutes les requêtes. Cette métrique est appropriée si vous êtes intéressé par la recommandation unique la mieux classée.\n",
    "- normalized_discounted_cumulative_gain_at_K : Le gain actualisé suppose que les recommandations situées plus bas dans une liste de recommandations sont moins pertinentes que les recommandations situées plus haut. Par conséquent, chaque recommandation est réduite (pondération plus faible) par un facteur dépendant de sa position. Pour produire le [gain cumulé actualisé](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) (DCG) à K, toutes les recommandations actualisées pertinentes dans les K premières recommandations sont additionnées. Le gain cumulé actualisé normalisé (NDCG) est le DCG divisé par le DCG idéal de sorte que le NDCG soit compris entre 0 et 1. (Le DCG idéal est celui où les K premières recommandations sont triées par pertinence). Amazon Personalize utilise un facteur de pondération de 1/log(1 + position), où le haut de la liste est la position 1. Cette métrique récompense les articles pertinents qui apparaissent près du haut de la liste, car le haut d'une liste suscite généralement plus d'attention.\n",
    "- precision_at_K : Le nombre de recommandations pertinentes parmi les K premières recommandations divisé par K. Cette métrique récompense la recommandation précise des articles pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer et attendre la campagne\n",
    "\n",
    "Maintenant que vous avez une version de la solution opérationnelle, vous devez créer une campagne pour l'utiliser avec vos applications. Une campagne est une version de la solution hébergée, un point de terminaison que vous pouvez interroger pour obtenir des recommandations. La tarification est fixée en estimant la capacité de débit (demandes de personnalisation de l'utilisateur par seconde). Lors du déploiement d'une campagne, vous définissez une valeur minimale de transactions par seconde (TPS) (`minProvisionedTPS`). Ce service, comme beaucoup d'autres au sein d'AWS, évoluera automatiquement en fonction de la demande. Néanmoins, si la latence est stratégique, vous voudrez peut-être prendre des dispositions pour une demande plus importante. Pour cette démo, le seuil de débit minimum est défini à 1. Pour plus d'informations, reportez-vous à la page de [tarification](https://aws.amazon.com/personalize/pricing/).\n",
    "\n",
    "Comme mentionné ci-dessus, la recette de personnalisation de l'utilisateur utilisée pour notre solution prend en charge l'exploration automatique des articles \"cold\". Vous pouvez contrôler le niveau d'exploration lors de la création de votre campagne. Le type de données `itemExplorationConfig` prend en charge les paramètres `explorationWeight` et `explorationItemAgeCutOff`. La pondération de l'exploration détermine la fréquence à laquelle les recommandations incluent les articles dont les données d'interaction ou la pertinence sont moindres. Plus la valeur est proche de 1,0, plus l'exploration est forte. À zéro, aucune exploration n'a lieu et les recommandations sont basées sur les données actuelles (pertinence). Le critère d'âge des articles à explorer détermine les articles à explorer en fonction du temps écoulé depuis la dernière interaction. Fournir l'âge maximal de l'article, en jours depuis la dernière interaction, pour définir la portée de l'exploration de l'article. Plus la valeur est élevée, plus le nombre d'articles pris en compte lors de l'exploration est élevé. Pour notre campagne ci-dessous, nous allons spécifier une pondération d'exploration de 0,5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une campagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_campaign(solution, name):\n",
    "    create_campaign_response = personalize.create_campaign(\n",
    "        name = \"personalize-demo-\" + name + '-' + suffix,\n",
    "        solutionVersionArn = solution['solution_version_arn'],\n",
    "        minProvisionedTPS = 1,\n",
    "        campaignConfig = {\n",
    "            \"itemExplorationConfig\": {\n",
    "                \"explorationWeight\": \"0.5\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    campaign_arn = create_campaign_response['campaignArn']\n",
    "    print('campaign_arn:' + campaign_arn)\n",
    "    return campaign_arn\n",
    "\n",
    "def waitForCampaign(solution):\n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        describe_campaign_response = personalize.describe_campaign(\n",
    "            campaignArn = solution['campaign_arn']\n",
    "        )\n",
    "        status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "        print(\"Campaign: {} {}\".format(solution['campaign_arn'], status))\n",
    "\n",
    "        if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "            break\n",
    "\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer trois campagnes\n",
    "Créer une campagne pour chacune des optimisations des objectifs, mais garder tous les autres paramètres identiques pour démontrer l'impact de l'optimisation des objectifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_solution['campaign_arn'] = create_campaign(high_solution, 'high')\n",
    "low_solution['campaign_arn'] = create_campaign(low_solution, 'low')\n",
    "no_objective_optimization_solution['campaign_arn'] = create_campaign(no_objective_optimization_solution, 'max_relevance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la campagne ait le statut ACTIF\n",
    "\n",
    "Cela devrait prendre environ 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitForCampaign(high_solution)\n",
    "waitForCampaign(low_solution)\n",
    "waitForCampaign(no_objective_optimization_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir des exemples de recommandations\n",
    "\n",
    "Une fois la campagne active, vous êtes prêt à recevoir des recommandations. Tout d'abord, nous devons sélectionner un utilisateur aléatoire à partir de la collection. Ensuite, nous créerons quelques fonctions d'aide pour obtenir des informations sur les films à afficher pour les recommandations au lieu de simples ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a random user:\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "print(\"USER: {}\".format(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_movie_title(movie_id):\n",
    "    \"\"\"\n",
    "    Takes in an ID, returns a title\n",
    "    \"\"\"\n",
    "    movie_id = int(movie_id)-1\n",
    "    return items.iloc[movie_id]['TITLE'] + '(' + f'{-1*items.iloc[movie_id][\"ROYALTY\"]:.2f}'+ ')'\n",
    "\n",
    "def get_movie_royalty(movie_id):\n",
    "    \"\"\"\n",
    "    Takes in an ID, returns a title\n",
    "    \"\"\"\n",
    "    movie_id = int(movie_id)-1\n",
    "    return -1*items.iloc[movie_id][\"ROYALTY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appeler GetRecommendations\n",
    "\n",
    "En utilisant l'utilisateur que vous avez obtenu ci-dessus, les lignes ci-dessous obtiendront des recommandations pour vous et retourneront la liste des films recommandés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(solution):\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = solution['campaign_arn'],\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "    # Update DF rendering\n",
    "    pd.set_option('display.max_rows', 30)\n",
    "\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "\n",
    "    recommendation_list = []\n",
    "\n",
    "    total_royalties = 0.0\n",
    "    \n",
    "    for item in item_list:\n",
    "        title = get_movie_title(item['itemId'])\n",
    "        total_royalties = total_royalties + get_movie_royalty(item['itemId'])\n",
    "        recommendation_list.append(title)\n",
    "        \n",
    "    recommendation_list.append('TOTAL ROYALTIES: '+ f'{total_royalties:.2f}')\n",
    "    return recommendation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparer les recommandations\n",
    "Créer un ensemble de recommandations pour le même utilisateur afin de comparer l'impact de l'optimisation des objectifs.\n",
    "\n",
    "Remarquez l'impact de la valeur de la redevance indiquée entre parenthèses après le titre et l'année. Les films très bien notés et à forte redevance dont l'optimisation objective est désactivée ont tendance à apparaître plus bas dans la liste, voire pas du tout, lorsque l'optimisation objective est activée. \n",
    "\n",
    "Remarquez également les redevances totales pour tous les titres de chaque série de recommandations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df = pd.DataFrame(get_recommendations(no_objective_optimization_solution), columns = ['ObjectiveOff'])\n",
    "recommendations_df['LowObjective'] = get_recommendations(low_solution)\n",
    "recommendations_df['HighObjective'] = get_recommendations(high_solution)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examiner\n",
    "\n",
    "Le bloc-notes présente un exemple où le moteur de recommandation de films tient compte des redevances à payer pour un titre donné. En incluant cette pondération dans l'algorithme de recommandation, le service de streaming peut fournir de bonnes recommandations à un utilisateur, mais aussi minimiser les redevances à payer aux créateurs de contenu.\n",
    "\n",
    "Remarquez dans le graphique ci-dessus que, lorsque l'optimisation de l'objectif est désactivée, les frais de redevance entre parenthèses sont répartis assez uniformément, comme on peut s'y attendre puisqu'ils ne sont pas pris en compte. Cependant, dans la colonne LowObjective, les valeurs sont plus faibles et la somme des redevances est la plus basse pour le paramètre d'optimisation de l'objectif le plus élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer\n",
    "\n",
    "Nettoyer les ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_campaign(campaign_arn):\n",
    "    delete_campaign_result = personalize.delete_campaign(campaignArn=campaign_arn )\n",
    "    \n",
    "\n",
    "def wait_for_delete_campaign(campaign_arn):\n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        try:\n",
    "            describe_campaign_response = personalize.describe_campaign(\n",
    "                campaignArn = campaign_arn\n",
    "            )\n",
    "            status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "            print(\"campaign: {}\".format(status))\n",
    "\n",
    "        except ClientError as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        time.sleep(10)\n",
    "    print('campaign ' + campaign_arn + ' deleted')\n",
    "    \n",
    "def delete_solution(solution_arn):\n",
    "    delete_solution_result = personalize.delete_solution(solutionArn=solution_arn )\n",
    "    \n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "\n",
    "def wait_for_delete_solution(solution_arn):\n",
    "    while time.time() < max_time:\n",
    "        \n",
    "        try:\n",
    "            describe_solution_response = personalize.describe_solution(\n",
    "                solutionArn = solution_arn\n",
    "            )\n",
    "            status = describe_solution_response[\"solution\"][\"status\"]\n",
    "            print(\"Solution: {}\".format(status))\n",
    "\n",
    "        except ClientError:\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    print('Solution ' + solution_arn + ' deleted')\n",
    "    \n",
    "def delete_dataset(dataset_arn):\n",
    "    delete_dataset_result = personalize.delete_dataset(datasetArn=dataset_arn )\n",
    "    \n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        try:\n",
    "            describe_dataset_response = personalize.describe_dataset(\n",
    "                datasetArn = dataset_arn\n",
    "            )\n",
    "            status = describe_dataset_response[\"dataset\"][\"status\"]\n",
    "            print(\"dataset: {}\".format(status))\n",
    "\n",
    "        except ClientError:\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    print('dataset ' + dataset_arn + ' deleted')\n",
    "    \n",
    "def delete_schema(schema_arn):\n",
    "    delete_schema_result = personalize.delete_schema(schemaArn=schema_arn )\n",
    "    \n",
    "\n",
    "    print('schema ' + schema_arn + ' deleted')\n",
    "    \n",
    "def delete_dataset_group(dataset_group_arn):\n",
    "    delete_dataset_group_result = personalize.delete_dataset_group(datasetGroupArn=dataset_group_arn )\n",
    "    \n",
    "    max_time = time.time() + 3*60*60 # 3 hours\n",
    "    while time.time() < max_time:\n",
    "        try:\n",
    "            describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "                datasetGroupArn = dataset_group_arn\n",
    "            )\n",
    "            status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "            print(\"dataset_group: {}\".format(status))\n",
    "\n",
    "        except ClientError:\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    print('dataset_group ' + dataset_group_arn + ' deleted')\n",
    "    \n",
    "def delete_all(solutions):\n",
    "    for solution in solutions:\n",
    "        delete_campaign(solution['campaign_arn'])\n",
    "        \n",
    "    for solution in solutions:\n",
    "        wait_for_delete_campaign(solution['campaign_arn'])\n",
    "    for solution in solutions:\n",
    "        delete_solution(solution['solution_arn'])\n",
    "    for solution in solutions:\n",
    "        wait_for_delete_solution(solution['solution_arn'])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all([no_objective_optimization_solution, low_solution, high_solution] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset(item_dataset_arn)\n",
    "delete_dataset(interaction_dataset_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_schema(item_schema_arn)\n",
    "delete_schema(schema_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset_group(dataset_group_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "iam.detach_role_policy(RoleName=role_name, PolicyArn='arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess')\n",
    "iam.detach_role_policy(RoleName=role_name, PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess')\n",
    "time.sleep(10) # propogation time\n",
    "\n",
    "iam.delete_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 rm --recursive s3://$bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.delete_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
