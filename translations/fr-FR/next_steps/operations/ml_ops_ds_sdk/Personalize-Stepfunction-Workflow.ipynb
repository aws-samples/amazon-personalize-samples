{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendre opérationnel le processus de déploiement du modèle Amazon Personalize de bout en bout à l'aide du kit SDK AWS Step Functions Data Science\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Configuration](#Setup)\n",
    "3. [États Task](#Task-States)\n",
    "4. [États Wait](#Wait-States)\n",
    "5. [États Choice](#Choice-States)\n",
    "6. [Flux](#Workflow)\n",
    "7. [Générer des recommandations](#Generate-Recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ce manuel décrit l'utilisation du kit SDK AWS Step Functions Data Science pour créer et gérer un flux Amazon Personalize. Le kit SDK Step Functions est une bibliothèque open source qui permet aux scientifiques des données de créer et d'exécuter facilement des flux de machine learning à l'aide d'AWS Step Functions. Pour en savoir plus sur le kit SDK Step Functions, reportez-vous à la documentation suivante :\n",
    "* [AWS Step Functions](https://aws.amazon.com/step-functions/)\n",
    "* [AWS Step Functions : Guide du développeur](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html)\n",
    "* [Kit SDK AWS Step Functions Data Science](https://aws-step-functions-data-science-sdk.readthedocs.io)\n",
    "\n",
    "Dans ce manuel, nous allons utiliser le kit SDK pour créer des étapes afin de créer des ressources Amazon Personalize, les relier afin de créer un flux et exécuter ce flux dans AWS Step Functions. \n",
    "\n",
    "Pour en savoir plus sur Amazon Personalize, reportez-vous à la documentation suivante :\n",
    "\n",
    "* [Amazon Personalize](https://aws.amazon.com/personalize/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les modules requis à partir du kit SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "\n",
    "import stepfunctions\n",
    "import logging\n",
    "\n",
    "from stepfunctions.steps import *\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "stepfunctions.set_stream_logger(level=logging.INFO)\n",
    "\n",
    "workflow_execution_role = \"<Workflow exection role name>\" # paste the StepFunctionsWorkflowExecutionRole ARN from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurer l'emplacement et le nom du fichier S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"<Bucket Name>\"       # replace with the name of your S3 bucket\n",
    "filename = \"<File Name>\"  # replace with a name that you want to save the dataset under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurer les rôles IAM\n",
    "\n",
    "#### Créer un rôle d'exécution pour Step Functions\n",
    "\n",
    "Pour pouvoir créer et exécuter des flux dans Step Functions, vous avez besoin d'un rôle d'exécution.\n",
    "\n",
    "1. Accédez à la [console IAM](https://console.aws.amazon.com/iam/)\n",
    "2. Sélectionnez **Roles** (Rôles), puis **Create role** (Créer un rôle).\n",
    "3. Sous **Choose the service that will use this role** (Choisir le service qui utilisera ce rôle), sélectionnez **Step Functions**\n",
    "4. Choisissez **Next** (Suivant) jusqu'à ce que vous puissiez entrer un **Role name** (Nom de rôle)\n",
    "5. Saisissez un nom tel que `StepFunctionsWorkflowExecutionRole`, puis sélectionnez **Create role** (Créer un rôle)\n",
    "\n",
    "\n",
    "Associez une politique au rôle que vous avez créé. Les étapes suivantes associent une politique qui fournit un accès complet à Step Functions. Toutefois, en guise de bonne pratique, vous ne devez fournir l'accès qu'aux ressources dont vous avez besoin.  \n",
    "\n",
    "1. Sous l'onglet **Permissions** (Autorisations), cliquez sur **Add inline policy** (Ajouter une politique intégrée)\n",
    "2. Saisissez ce qui suit dans l'onglet **JSON**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "    \n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"personalize:*\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },   \n",
    "\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"lambda:InvokeFunction\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. Choisissez **Review policy** (Examiner la politique), puis donnez-lui un nom tel que `StepFunctionsWorkflowExecutionPolicy`\n",
    "4. Choisissez **Create policy** (Créer une politique). Vous serez redirigé vers la page de détails du rôle.\n",
    "5. Copiez **Role ARN** (ARN du rôle) au-dessus de **Summary** (Résumé)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_role = LambdaStep(\n",
    "    state_id=\"create bucket and role\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_create_personalize_role\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"bucket\": bucket\n",
    "        }\n",
    "    },\n",
    "    result_path='$'\n",
    " \n",
    ")\n",
    "\n",
    "lambda_state_role.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_role.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateRoleTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attacher une politique au compartiment S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "                \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un rôle Personalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"<Role Name>\" # Create a personalize role\n",
    "\n",
    "\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Télécharger, préparer et charger les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['RATING'] > 2]                # keep only movies rated 2 and above\n",
    "data2 = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] \n",
    "data2.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## États Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### État Task Lambda\n",
    "\n",
    "Un état `Task` dans Step Functions représente une unité de travail unique effectuée par un flux. Les tâches peuvent appeler des fonctions Lambda et orchestrer d'autres services AWS. Reportez-vous à la section [Intégration des services AWS](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-service-integrations.html) dans le *Guide du développeur AWS Step Functions*.\n",
    "\n",
    "Les étapes qui suivent permettent de créer un [LambdaStep](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/compute.html#stepfunctions.steps.compute.LambdaStep) appelé `lambda_state`, puis de configurer les options afin de [Réessayer](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-error-handling.html#error-handling-retrying-after-an-error) si la fonction Lambda échoue.\n",
    "\n",
    "#### Créer une fonction Lambda\n",
    "\n",
    "Les états Task Lambda de ce flux utilisent la fonction Lambda **(Python 3.x)** qui renvoie des ressources Amazon Personalize telles que Schema (Schéma), Datasetgroup (Groupe de jeux de données), Dataset (Jeu de donées), Solution (Solution), SolutionVersion (Version de la solution), etc. Créez les fonctions suivantes dans la [console Lambda](https://console.aws.amazon.com/lambda/).\n",
    "\n",
    "1. stepfunction-create-schema\n",
    "2. stepfunctioncreatedatagroup\n",
    "3. stepfunctioncreatedataset\n",
    "4. stepfunction-createdatasetimportjob\n",
    "5. stepfunction_select-recipe_create-solution\n",
    "6. stepfunction_create_solution_version\n",
    "7. stepfunction_getsolution_metric_create_campaign\n",
    "\n",
    "Faites un copier-coller du code de la fonction Lambda correspondant à partir du dossier ./Lambda/ dans le référentiel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_schema = LambdaStep(\n",
    "    state_id=\"create schema\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction-create-schema\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"input\": \"personalize-stepfunction-schema263\"\n",
    "        }\n",
    "    },\n",
    "    result_path='$'    \n",
    ")\n",
    "\n",
    "lambda_state_schema.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_schema.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateSchemaTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un groupe de jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_datasetgroup = LambdaStep(\n",
    "    state_id=\"create dataset Group\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunctioncreatedatagroup\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"input\": \"personalize-stepfunction-dataset-group\", \n",
    "           \"schemaArn.$\": '$.Payload.schemaArn'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    result_path='$'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "lambda_state_datasetgroup.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "\n",
    "lambda_state_datasetgroup.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateDataSetGroupTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_createdataset = LambdaStep(\n",
    "    state_id=\"create dataset\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunctioncreatedataset\", #replace with the name of the function you created\n",
    "#        \"Payload\": {  \n",
    "#           \"schemaArn.$\": '$.Payload.schemaArn',\n",
    "#           \"datasetGroupArn.$\": '$.Payload.datasetGroupArn',\n",
    "            \n",
    "            \n",
    "#        }\n",
    "        \n",
    "        \"Payload\": {  \n",
    "           \"schemaArn.$\": '$.schemaArn',\n",
    "           \"datasetGroupArn.$\": '$.datasetGroupArn',        \n",
    "        } \n",
    "        \n",
    "        \n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_createdataset.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_createdataset.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateDataSetTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une tâche d'importation de jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_datasetimportjob = LambdaStep(\n",
    "    state_id=\"create dataset import job\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction-createdatasetimportjob\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"datasetimportjob\": \"stepfunction-createdatasetimportjob\",\n",
    "           \"dataset_arn.$\": '$.Payload.dataset_arn',\n",
    "           \"datasetGroupArn.$\": '$.Payload.datasetGroupArn',\n",
    "           \"bucket_name\": bucket,\n",
    "           \"file_name\": filename,\n",
    "           \"role_arn\": role_arn\n",
    "            \n",
    "        }\n",
    "    },\n",
    "\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_datasetimportjob.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_datasetimportjob.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"DatasetImportJobTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une recette et une solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_select_receipe_create_solution = LambdaStep(\n",
    "    state_id=\"select receipe and create solution\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_select-recipe_create-solution\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           #\"dataset_group_arn.$\": '$.Payload.datasetGroupArn' \n",
    "            \"dataset_group_arn.$\": '$.datasetGroupArn'\n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_select_receipe_create_solution.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_select_receipe_create_solution.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"DatasetReceiptCreateSolutionTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une version de solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_create_solution_version = LambdaStep(\n",
    "    state_id=\"create solution version\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_create_solution_version\", \n",
    "        \"Payload\": {  \n",
    "           \"solution_arn.$\": '$.Payload.solution_arn'           \n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_create_solution_version.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_create_solution_version.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateSolutionVersionTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une campagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_create_campaign = LambdaStep(\n",
    "    state_id=\"create campaign\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_getsolution_metric_create_campaign\", \n",
    "        \"Payload\": {  \n",
    "            #\"solution_version_arn.$\": '$.Payload.solution_version_arn'  \n",
    "            \"solution_version_arn.$\": '$.solution_version_arn'\n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_create_campaign.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_create_campaign.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CreateCampaignTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## États Wait\n",
    "\n",
    "#### Un état `Wait` dans Step Functions attend un laps de temps spécifique. Référez-vous à la section [Attendre](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/states.html#stepfunctions.steps.states.Wait) de la documentation du kit SDK AWS Step Functions Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que le schéma soit prêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_schema = Wait(\n",
    "    state_id=\"Wait for create schema - 5 secs\",\n",
    "    seconds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que le groupe de jeux de données soit prêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_datasetgroup = Wait(\n",
    "    state_id=\"Wait for datasetgroup - 30 secs\",\n",
    "    seconds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que le jeu de données soit prêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_dataset = Wait(\n",
    "    state_id=\"wait for dataset - 30 secs\",\n",
    "    seconds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la tâche d'importation de jeux de données soit ACTIVE (ACTIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_datasetimportjob = Wait(\n",
    "    state_id=\"Wait for datasetimportjob - 30 secs\",\n",
    "    seconds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la recette soit prête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_receipe = Wait(\n",
    "    state_id=\"Wait for receipe - 30 secs\",\n",
    "    seconds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la version de la solution soit ACTIVE (ACTIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_solutionversion = Wait(\n",
    "    state_id=\"Wait for solution version - 60 secs\",\n",
    "    seconds=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la campagne soit ACTIVE (ACTIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_state_campaign = Wait(\n",
    "    state_id=\"Wait for Campaign - 30 secs\",\n",
    "    seconds=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Vérifier l'état de la tâche Lambda et agir en conséquence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si un état échoue, transférez-le vers l'état `Fail`. Référez-vous à la section [Échec](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/states.html#stepfunctions.steps.states.Fail) de la documentation du kit SDK AWS Step Functions Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vérifier l'état du groupe de jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_datasetgroupstatus = LambdaStep(\n",
    "    state_id=\"check dataset Group status\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_waitforDatasetGroup\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"input.$\": '$.Payload.datasetGroupArn',\n",
    "           \"schemaArn.$\": '$.Payload.schemaArn'\n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_datasetgroupstatus.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_datasetgroupstatus.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"DatasetGroupStatusTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vérifier l'état de la tâche d'importation de jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_datasetimportjob_status = LambdaStep(\n",
    "    state_id=\"check dataset import job status\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_waitfordatasetimportjob\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"dataset_import_job_arn.$\": '$.Payload.dataset_import_job_arn',\n",
    "           \"datasetGroupArn.$\": '$.Payload.datasetGroupArn'\n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_datasetimportjob_status.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_datasetimportjob_status.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"DatasetImportJobStatusTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vérifier l'état de la version de la solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "solutionversion_succeed_state = Succeed(\n",
    "    state_id=\"The Solution Version ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_solutionversion_status = LambdaStep(\n",
    "    state_id=\"check solution version status\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_waitforSolutionVersion\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"solution_version_arn.$\": '$.Payload.solution_version_arn'           \n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_solutionversion_status.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_solutionversion_status.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"SolutionVersionStatusTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vérifier l'état de la campagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_campaign_status = LambdaStep(\n",
    "    state_id=\"check campaign status\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_waitforCampaign\", #replace with the name of the function you created\n",
    "        \"Payload\": {  \n",
    "           \"campaign_arn.$\": '$.Payload.campaign_arn'           \n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_campaign_status.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_campaign_status.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"CampaignStatusTaskFailed\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## États Choice\n",
    "\n",
    "À présent, associez des branches à l'état Choice que vous avez créé précédemment. Référez-vous à la section *Règles de choix* de la documentation du kit SDK [AWS Step Functions Data Science](https://aws-step-functions-data-science-sdk.readthedocs.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relier les étapes à l'aide d'une chaîne pour définir le chemin du flux\n",
    "\n",
    "La cellule suivante relie les étapes que vous avez créées ci-dessus dans un groupe séquentiel. Le nouveau chemin inclut successivement l'état Lambda, l'état Wait et l'état Succeed que vous avez créés précédemment.\n",
    "\n",
    "#### Après avoir relié les étapes du chemin du flux à l'aide d'une chaîne, nous allons définir et visualiser le flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_choice_state = Choice(\n",
    "    state_id=\"Is the Campaign ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_choice_state.add_choice(\n",
    "    rule=ChoiceRule.StringEquals(variable=lambda_state_campaign_status.output()['Payload']['status'], value='ACTIVE'),\n",
    "    next_step=Succeed(\"CampaignCreatedSuccessfully\")     \n",
    ")\n",
    "create_campaign_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_campaign_status.output()['Payload']['status'], value='CREATE PENDING'),\n",
    "    next_step=wait_state_campaign\n",
    ")\n",
    "create_campaign_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_campaign_status.output()['Payload']['status'], value='CREATE IN_PROGRESS'),\n",
    "    next_step=wait_state_campaign\n",
    ")\n",
    "\n",
    "create_campaign_choice_state.default_choice(next_step=Fail(\"CreateCampaignFailed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutionversion_choice_state = Choice(\n",
    "    state_id=\"Is the Solution Version ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutionversion_succeed_state = Succeed(\n",
    "    state_id=\"The Solution Version ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutionversion_choice_state.add_choice(\n",
    "    rule=ChoiceRule.StringEquals(variable=lambda_state_solutionversion_status.output()['Payload']['status'], value='ACTIVE'),\n",
    "    next_step=solutionversion_succeed_state   \n",
    ")\n",
    "solutionversion_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_solutionversion_status.output()['Payload']['status'], value='CREATE PENDING'),\n",
    "    next_step=wait_state_solutionversion\n",
    ")\n",
    "solutionversion_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_solutionversion_status.output()['Payload']['status'], value='CREATE IN_PROGRESS'),\n",
    "    next_step=wait_state_solutionversion\n",
    ")\n",
    "\n",
    "solutionversion_choice_state.default_choice(next_step=Fail(\"create_solution_version_failed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetimportjob_succeed_state = Succeed(\n",
    "    state_id=\"The Solution Version ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetimportjob_choice_state = Choice(\n",
    "    state_id=\"Is the DataSet Import Job ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetimportjob_choice_state.add_choice(\n",
    "    rule=ChoiceRule.StringEquals(variable=lambda_state_datasetimportjob_status.output()['Payload']['status'], value='ACTIVE'),\n",
    "    next_step=datasetimportjob_succeed_state   \n",
    ")\n",
    "datasetimportjob_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_datasetimportjob_status.output()['Payload']['status'], value='CREATE PENDING'),\n",
    "    next_step=wait_state_datasetimportjob\n",
    ")\n",
    "datasetimportjob_choice_state.add_choice(\n",
    "    ChoiceRule.StringEquals(variable=lambda_state_datasetimportjob_status.output()['Payload']['status'], value='CREATE IN_PROGRESS'),\n",
    "    next_step=wait_state_datasetimportjob\n",
    ")\n",
    "\n",
    "\n",
    "datasetimportjob_choice_state.default_choice(next_step=Fail(\"dataset_import_job_failed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetgroupstatus_choice_state = Choice(\n",
    "    state_id=\"Is the DataSetGroup ready?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définir le flux\n",
    "\n",
    "Dans la cellule suivante, définissez l'étape que vous souhaitez utiliser dans le flux.  Ensuite, créez, visualisez et exécuter ce flux. \n",
    "\n",
    "Les étapes se rapportent aux états dans AWS Step Functions. Pour en savoir plus, reportez-vous à la section [États](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-states.html) dans le *Guide du développer AWS Step Functions*. Pour en savoir plus sur les API du kit SDK AWS Step Functions Data Science, rendez-vous sur la page : https://aws-step-functions-data-science-sdk.readthedocs.io. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux du jeu de donnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_workflow_definition=Chain([lambda_state_schema,\n",
    "                                   wait_state_schema,\n",
    "                                   lambda_state_datasetgroup,\n",
    "                                   wait_state_datasetgroup,\n",
    "                                   lambda_state_datasetgroupstatus\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_workflow = Workflow(\n",
    "    name=\"Dataset-workflow\",\n",
    "    definition=Dataset_workflow_definition,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetWorkflowArn = Dataset_workflow.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux de l'importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetImport_workflow_definition=Chain([lambda_state_createdataset,\n",
    "                                   wait_state_dataset,\n",
    "                                   lambda_state_datasetimportjob,\n",
    "                                   wait_state_datasetimportjob,\n",
    "                                   lambda_state_datasetimportjob_status,\n",
    "                                   datasetimportjob_choice_state\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetImport_workflow = Workflow(\n",
    "    name=\"DatasetImport-workflow\",\n",
    "    definition=DatasetImport_workflow_definition,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetImport_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetImportflowArn = DatasetImport_workflow.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux de la recette et de la solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_receipe_sol_workflow_definition=Chain([lambda_state_select_receipe_create_solution,\n",
    "                                   wait_state_receipe,\n",
    "                                   lambda_create_solution_version,\n",
    "                                   wait_state_solutionversion,\n",
    "                                   lambda_state_solutionversion_status,\n",
    "                                   solutionversion_choice_state\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_receipe_sol_workflow = Workflow(\n",
    "    name=\"Create_receipe_sol-workflow\",\n",
    "    definition=Create_receipe_sol_workflow_definition,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_receipe_sol_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateReceipeArn = Create_receipe_sol_workflow.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un flux de campagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_Campaign_workflow_definition=Chain([lambda_create_campaign,\n",
    "                                   wait_state_campaign,\n",
    "                                   lambda_state_campaign_status,\n",
    "                                   wait_state_datasetimportjob,\n",
    "                                   create_campaign_choice_state\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Campaign_workflow = Workflow(\n",
    "    name=\"Campaign-workflow\",\n",
    "    definition=Create_Campaign_workflow_definition,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Campaign_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateCampaignArn = Campaign_workflow.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_dataset_workflow_state = Task(\n",
    "    state_id=\"DataSetWorkflow\",\n",
    "    resource=\"arn:aws:states:::states:startExecution.sync:2\",\n",
    "    parameters={\n",
    "                                \"Input\": \"true\",\n",
    "                                #\"StateMachineArn\": \"arn:aws:states:us-east-1:444602785259:stateMachine:Dataset-workflow\",\n",
    "                                \"StateMachineArn\": DatasetWorkflowArn\n",
    "                }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_datasetImport_workflow_state = Task(\n",
    "    state_id=\"DataSetImportWorkflow\",\n",
    "    resource=\"arn:aws:states:::states:startExecution.sync:2\",\n",
    "    parameters={\n",
    "                                 \"Input\":{\n",
    "                                    \"schemaArn.$\": \"$.Output.Payload.schemaArn\",\n",
    "                                    \"datasetGroupArn.$\": \"$.Output.Payload.datasetGroupArn\"\n",
    "                                   },\n",
    "                                \"StateMachineArn\": DatasetImportflowArn,\n",
    "                }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_receipe_solution_workflow_state = Task(\n",
    "    state_id=\"ReceipeSolutionWorkflow\",\n",
    "    resource=\"arn:aws:states:::states:startExecution.sync:2\",\n",
    "    parameters={\n",
    "                                 \"Input\":{\n",
    "                                    \"datasetGroupArn.$\": \"$.Output.Payload.datasetGroupArn\"\n",
    "\n",
    "                                   },\n",
    "                                \"StateMachineArn\": CreateReceipeArn\n",
    "                }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_campaign_solution_workflow_state = Task(\n",
    "    state_id=\"CampaignWorkflow\",\n",
    "    resource=\"arn:aws:states:::states:startExecution.sync:2\",\n",
    "    parameters={\n",
    "                                 \"Input\":{\n",
    "                                    \"solution_version_arn.$\": \"$.Output.Payload.solution_version_arn\"\n",
    "\n",
    "                                   },\n",
    "                                \"StateMachineArn\": CreateCampaignArn\n",
    "                }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow_definition=Chain([call_dataset_workflow_state,\n",
    "                                call_datasetImport_workflow_state,\n",
    "                                call_receipe_solution_workflow_state,\n",
    "                                call_campaign_solution_workflow_state\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow = Workflow(\n",
    "    name=\"Main-workflow\",\n",
    "    definition=Main_workflow_definition,\n",
    "    role=workflow_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow_execution = Main_workflow.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main_workflow_execution = Workflow(\n",
    "    name=\"Campaign_Workflow\",\n",
    "    definition=path1,\n",
    "    role=workflow_execution_role\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main_workflow_execution.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer et exécuter le flux\n",
    "\n",
    "Dans les cellules suivantes, nous allons créer une ramification de flux « happy » dans AWS Step Functions avec [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create), puis l'exécuter avec [execute](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.execute).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalize_workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalize_workflow_execution = happy_workflow.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Passer en revue la progression du flux\n",
    "\n",
    "Passez en revue la progression du flux à l'aide de [render_progress](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Execution.render_progress).\n",
    "\n",
    "Passez en revue l'historique d'exécution en appelant [list_events](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Execution.list_events) pour répertorier tous les événements d'exécution du flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow_execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_workflow_execution.list_events(html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer des recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### À présent que notre campagne a abouti, générons des recommandations pour la campagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélectionner un utilisateur et un article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], encoding='latin-1')\n",
    "items.columns = ['ITEM_ID', 'TITLE']\n",
    "\n",
    "\n",
    "user_id, item_id, rating, timestamp = data.sample().values[0]\n",
    "\n",
    "user_id = int(user_id)\n",
    "item_id = int(item_id)\n",
    "\n",
    "print(\"user_id\",user_id)\n",
    "print(\"items\",items)\n",
    "\n",
    "\n",
    "item_title = items.loc[items['ITEM_ID'] == item_id].values[0][-1]\n",
    "print(\"USER: {}\".format(user_id))\n",
    "print(\"ITEM: {}\".format(item_title))\n",
    "print(\"ITEM ID: {}\".format(item_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_recommendations = Wait(\n",
    "    state_id=\"Wait for recommendations - 10 secs\",\n",
    "    seconds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tâche Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_state_get_recommendations = LambdaStep(\n",
    "    state_id=\"get recommendations\",\n",
    "    parameters={  \n",
    "        \"FunctionName\": \"stepfunction_getRecommendations\", \n",
    "        \"Payload\": {  \n",
    "           \"campaign_arn\": 'arn:aws:personalize:us-east-1:261602857181:campaign/stepfunction-campaign',            \n",
    "           \"user_id\": user_id,  \n",
    "           \"item_id\": item_id             \n",
    "        }\n",
    "    },\n",
    "    result_path = '$'\n",
    ")\n",
    "\n",
    "lambda_state_get_recommendations.add_retry(Retry(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    interval_seconds=5,\n",
    "    max_attempts=1,\n",
    "    backoff_rate=4.0\n",
    "))\n",
    "\n",
    "lambda_state_get_recommendations.add_catch(Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=Fail(\"GetRecommendationTaskFailed\")\n",
    "    #next_step=recommendation_path   \n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un état Succeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_complete = Succeed(\"WorkflowComplete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_path = Chain([ \n",
    "lambda_state_get_recommendations,\n",
    "wait_recommendations,\n",
    "workflow_complete\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définir, créer, traduire et exécuter le flux de recommandation\n",
    "\n",
    "Dans les cellules suivantes, nous allons créer un flux dans AWS Step Functions avec [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create), puis l'exécuter avec [execute](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.execute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_workflow = Workflow(\n",
    "    name=\"Recommendation_Workflow4\",\n",
    "    definition=recommendation_path,\n",
    "    role=workflow_execution_role\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_workflow_execution = recommendation_workflow.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passer en revue la progression\n",
    "\n",
    "Passez en revue la progression du flux à l'aide de [render_progress](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Execution.render_progress).\n",
    "\n",
    "Passez en revue l'historique d'exécution en appelant [list_events](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Execution.list_events) pour répertorier tous les événements d'exécution du flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_workflow_execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recommendation_workflow_execution.list_events(html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = recommendation_workflow_execution.get_output()['Payload']['item_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir les recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = recommendation_workflow_execution.get_output()['Payload']['item_list']\n",
    "\n",
    "print(\"Recommendations:\")\n",
    "for item in item_list:\n",
    "    np.int(item['itemId'])\n",
    "    item_title = items.loc[items['ITEM_ID'] == np.int(item['itemId'])].values[0][-1]\n",
    "    print(item_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les ressources Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assurez-vous de nettoyer les ressources Amazon Personalize et le blog créé par les machines d'état. Connectez-vous à la console Amazon Personalize et supprimez des ressources telles Dataset Groups (Groupes de jeux de données), Dataset (Jeu de données), Solutions (Solutions), Receipts (Recettes) et Campaign (Campagne). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer les ressources de la machine d'état"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Campaign_workflow.delete()\n",
    "\n",
    "recommendation_workflow.delete()\n",
    "\n",
    "Main_workflow.delete()\n",
    "\n",
    "Create_receipe_sol_workflow.delete()\n",
    "\n",
    "DatasetImport_workflow.delete()\n",
    "\n",
    "Dataset_workflow.delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
