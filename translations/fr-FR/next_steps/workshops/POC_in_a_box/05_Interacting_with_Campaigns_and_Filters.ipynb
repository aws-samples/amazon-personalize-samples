{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction avec les campagnes <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "Dans ce bloc-notes, vous allez déployer et interagir avec les campagnes dans Amazon Personalize.\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "1. [Créer des campagnes](#create)\n",
    "1. [Interagir avec les campagnes](#interact)\n",
    "1. [Recommandations par lots](#batch)\n",
    "1. [Récapitulatif](#wrapup)\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "[Retour au début](#top)\n",
    "\n",
    "À ce stade, vous devriez avoir plusieurs solutions et au moins une version de solution pour chacune d'elles. Une fois qu'une version de la solution est créée, il est possible d'obtenir des recommandations de cette dernière et de s'imprégner de son comportement général.\n",
    "\n",
    "Ce bloc-notes déploie tout d'abord chacune des versions de la solution du bloc-notes précédent dans des campagnes individuelles. Une fois qu'elles sont actives, des ressources sont prévues pour interroger les recommandations, ainsi que des fonctions d'aide pour transformer le résultat en données plus lisibles par l'homme. \n",
    "\n",
    "Comme vous avec votre client sur Amazon Personalize, vous pouvez modifier les fonctions d'aide pour les adapter à la structure de leurs fichiers d'entrée de données afin que le rendu supplémentaire fonctionne.\n",
    "\n",
    "Pour commencer, nous devons une fois de plus importer des bibliothèques, charger les valeurs des bloc-notes précédents et charger le kit SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "# Establish a connection to Personalize's event streaming\n",
    "personalize_events = boto3.client(service_name='personalize-events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interagir avec les campagnes <a class=\"anchor\" id=\"interact\"></a>\n",
    "[Retour au début](#top)\n",
    "\n",
    "Maintenant que toutes les campagnes sont déployées et actives, nous pouvons obtenir des recommandations via un appel API. Chacune des campagnes est basée sur une recette différente, qui se comporte de manière légèrement différente, car elle répond à des cas d'utilisation différents. Nous aborderons chaque campagne dans un ordre différent de celui utilisé dans les bloc-notes précédents, afin de traiter les éventuelles complexités par ordre croissant (c'est-à-dire le plus simple en premier).\n",
    "\n",
    "Tout d'abord, créons une fonction de prise en charge pour faciliter la compréhension des résultats renvoyés par une campagne Personalize. Personalize renvoie uniquement un `item_id`. Cette méthode est très pratique pour conserver des données compactes, mais elle signifie que vous devez interroger une base de données ou une table de consultation pour obtenir un résultat lisible par l'homme pour les bloc-notes. Nous allons créer une fonction d'aide pour renvoyer un résultat lisible par l'homme à partir du jeu de données LastFM.\n",
    "\n",
    "Commencez par charger le jeu de données que nous pouvons utiliser pour notre table de consultation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the items by reading in the correct source CSV\n",
    "items_df = pd.read_csv(dataset_dir + '/movies.csv', sep=',', usecols=[0,1], encoding='latin-1', dtype={'movieId': \"object\", 'title': \"str\"},index_col=0)\n",
    "\n",
    "# Render some sample data\n",
    "items_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En définissant la colonne ID comme colonne d'index, il est aisé de trouver un artiste en recherchant simplement l'ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_example = 589\n",
    "title = items_df.loc[movie_id_example]['title']\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode est acceptable. Cependant, il serait fastidieux de la répéter partout dans notre code. C'est pourquoi la fonction ci-dessous va la supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_by_id(movie_id, movie_df=items_df):\n",
    "    \"\"\"\n",
    "    This takes in an artist_id from Personalize so it will be a string,\n",
    "    converts it to an int, and then does a lookup in a default or specified\n",
    "    dataframe.\n",
    "    \n",
    "    A really broad try/except clause was added in case anything goes wrong.\n",
    "    \n",
    "    Feel free to add more debugging or filtering here to improve results if\n",
    "    you hit an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return movie_df.loc[int(movie_id)]['title']\n",
    "    except:\n",
    "        return \"Error obtaining title\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent quelques valeurs simples pour vérifier notre système de détection d'erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A known good id (The Princess Bride)\n",
    "print(get_movie_by_id(movie_id=\"1197\"))\n",
    "# A bad type of value\n",
    "print(get_movie_by_id(movie_id=\"987.9393939\"))\n",
    "# Really bad values\n",
    "print(get_movie_by_id(movie_id=\"Steve\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super ! Nous disposons désormais d'un moyen de présentation des résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMS\n",
    "\n",
    "Il suffit de saisir un article pour que SIMS fournisse des articles avec lesquels les utilisateurs interagissent comme ils le font avec l'article saisi. Dans ce cas particulier, l'article est un film. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les cellules ci-dessous prennent en charge l'obtention des recommandations à partir de SIMS et la présentation des résultats. Voyons quelles sont les recommandations pour le premier article que nous avons examiné plus tôt dans ce bloc-notes (Terminator 2 : Le Jugement dernier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = sims_campaign_arn,\n",
    "    itemId = str(589),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = get_recommendations_response['itemList']\n",
    "for item in item_list:\n",
    "    print(get_movie_by_id(movie_id=item['itemId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Félicitations ! Ceci est votre première liste de recommandations. Cette liste est parfaite. Toutefois, il serait préférable de voir les recommandations de notre sélection d'artistes présentées dans un dans un tableau de données bien structuré. Nous allons à nouveau créer une fonction d'aide pour y parvenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "def get_new_recommendations_df(recommendations_df, movie_ID):\n",
    "    # Get the movie name\n",
    "    movie_name = get_movie_by_id(movie_ID)\n",
    "    # Get the recommendations\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = sims_campaign_arn,\n",
    "        itemId = str(movie_ID),\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        movie = get_movie_by_id(item['itemId'])\n",
    "        recommendation_list.append(movie)\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [movie_name])\n",
    "    # Add this dataframe to the old one\n",
    "    recommendations_df = pd.concat([recommendations_df, new_rec_DF], axis=1)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent la fonction d'aide avec plusieurs films différents. Testons notre campagne SIMS à partir de quelques données de notre jeu de données. Sélectionnez 5 films aléatoires dans notre tableau de données.\n",
    "\n",
    "Remarque : Nous présenterons des titres similaires. Vous pouvez donc relancer la démonstration jusqu'à ce que vous reconnaissiez certains des films listés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = items_df.sample(5)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_recommendations_df = pd.DataFrame()\n",
    "movies = samples.index.tolist()\n",
    "\n",
    "for movie in movies:\n",
    "    sims_recommendations_df = get_new_recommendations_df(sims_recommendations_df, movie)\n",
    "\n",
    "sims_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous remarquerez peut-être une ressemblance avec plusieurs articles, mais pas tous (la probabilité est plus grande avec un nombre réduit d'interactions, notamment avec le petit jeu de données movielens). Cela prouve que vous ne devez pas vous baser uniquement sur les métriques d'évaluation pour évaluer la version de votre solution. Que pouvez-vous donc faire pour améliorer les résultats en pareil cas ?\n",
    "\n",
    "Le moment est tout indiqué pour envisager les hyperparamètres des recettes Personalize. La recette SIMS comporte un hyperparamètre `popularity_discount_factor` (voir la [documentation](https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-sims.html)). L'utilisation de cet hyperparamètre vous permet de contrôler la nuance constatée dans les résultats. Ce paramètre et son comportement sont spécifiques à chaque jeu de données que vous rencontrez et dépendent des objectifs de l'entreprise. Vous pouvez répéter la valeur de cet hyperparamètre jusqu'à ce que vous soyez satisfait des résultats. Vous pouvez aussi commencer par utiliser la fonction d'optimisation des hyperparamètres (HPO) de Personalize. Pour en savoir plus sur les hyperparamètres et le paramétrage de HPO, reportez-vous à la [documentation](https://docs.aws.amazon.com/personalize/latest/dg/customizing-solution-config-hpo.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personnalisation de l'utilisateur\n",
    "\n",
    "HRNN est l'un des algorithmes les plus avancés fournis par Amazon Personalize. Il prend en charge la personnalisation des articles pour un utilisateur spécifique sur la base de son comportement passé et peut prendre en compte les événements en temps réel afin de modifier les recommandations pour un utilisateur sans nouvel entraînement. \n",
    "\n",
    "Le principe HRNN étant de disposer d'un échantillon d'utilisateurs, chargeons les données dont nous avons besoin pour cette opération et sélectionnons trois utilisateurs au hasard. Puisque MovieLens n'inclut pas de données sur les utilisateurs, nous allons sélectionner trois nombres aléatoires dans la gamme des identifiants d'utilisateurs du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_FULL_MOVIELENS:\n",
    "    users = random.sample(range(1, 600), 3)\n",
    "else:\n",
    "    users = random.sample(range(1, 162000), 3)\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous présentons ci-après les recommandations pour nos trois utilisateurs aléatoires. Nous explorerons ensuite les interactions en temps réel avant de passer au classement personnalisé.\n",
    "\n",
    "Nous créons à nouveau une fonction d'aide pour présenter les résultats dans un tableau de données bien structuré.\n",
    "\n",
    "#### Résultats des appels d'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "def get_new_recommendations_df_users(recommendations_df, user_id):\n",
    "    # Get the movie name\n",
    "    #movie_name = get_movie_by_id(artist_ID)\n",
    "    # Get the recommendations\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = userpersonalization_campaign_arn,\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        movie = get_movie_by_id(item['itemId'])\n",
    "        recommendation_list.append(movie)\n",
    "    #print(recommendation_list)\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [user_id])\n",
    "    # Add this dataframe to the old one\n",
    "    recommendations_df = pd.concat([recommendations_df, new_rec_DF], axis=1)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df_users = pd.DataFrame()\n",
    "#users = users_df.sample(3).index.tolist()\n",
    "\n",
    "for user in users:\n",
    "    recommendations_df_users = get_new_recommendations_df_users(recommendations_df_users, user)\n",
    "\n",
    "recommendations_df_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous voyons clairement que les recommandations sont différentes pour chaque utilisateur. Si vous aviez besoin d'un cache pour ces résultats, vous pourriez commencer par exécuter les appels d'API par tous vos utilisateurs et stocker les résultats. Vous pourriez aussi utiliser une exportation par lot. Cette approche qui sera abordée plus tard dans ce bloc-notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons à présent des filtres d'articles pour accéder aux recommandations pour l'un de ces utilisateurs au sein d'un genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_recommendations_df_by_filter(recommendations_df, user_id, filter_arn):\n",
    "    # Get the movie name\n",
    "    #movie_name = get_movie_by_id(artist_ID)\n",
    "    # Get the recommendations\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = userpersonalization_campaign_arn,\n",
    "        userId = str(user_id),\n",
    "        filterArn = filter_arn\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        movie = get_movie_by_id(item['itemId'])\n",
    "        recommendation_list.append(movie)\n",
    "    #print(recommendation_list)\n",
    "    filter_name = filter_arn.split('/')[1]\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [filter_name])\n",
    "    # Add this dataframe to the old one\n",
    "    recommendations_df = pd.concat([recommendations_df, new_rec_DF], axis=1)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez accéder aux recommandations de films dans un genre donné. Dans une application VOD, vous pouvez créer des répertoires (également appelés rails ou carrousels) facilement en utilisant ces filtres. En fonction des informations dont vous disposez sur vos articles, vous pouvez également filtrer selon des informations supplémentaires telles que le mot-clé, l'année/décennie, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df_shelves = pd.DataFrame()\n",
    "for filter_arn in meta_filter_arns:\n",
    "    recommendations_df_shelves = get_new_recommendations_df_by_filter(recommendations_df_shelves, user, filter_arn)\n",
    "for filter_arn in decade_filter_arns:\n",
    "    recommendations_df_shelves = get_new_recommendations_df_by_filter(recommendations_df_shelves, user, filter_arn)\n",
    "\n",
    "recommendations_df_shelves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine rubrique concerne les événements en temps réel. Personalize a la capacité de suivre les événements de votre application afin de mettre à jour les recommandations présentées à l'utilisateur. Cela est particulièrement utile pour les charges de travail liées aux médias, comme la vidéo à la demande, où l'intention du client peut différer selon qu'il regarde le film avec ses enfants ou seul.\n",
    "\n",
    "En outre, les événements enregistrés par l’intermédiaire de ce système sont stockés jusqu'à ce que vous émettiez un ordre de suppression, et ils sont utilisés comme données historiques avec les autres données d'interaction que vous avez fournies lors de la formation de vos prochains modèles.\n",
    "\n",
    "#### Événements en temps réel\n",
    "\n",
    "Commencez par créer un suivi d'événement qui est attaché à la campagne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = personalize.create_event_tracker(\n",
    "    name='MovieTracker',\n",
    "    datasetGroupArn=dataset_group_arn\n",
    ")\n",
    "print(response['eventTrackerArn'])\n",
    "print(response['trackingId'])\n",
    "TRACKING_ID = response['trackingId']\n",
    "event_tracker_arn = response['eventTrackerArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer un code qui simule l'interaction d'un utilisateur avec un article particulier. Après avoir exécuté ce code, vous obtiendrez des recommandations qui diffèrent des résultats ci-dessus.\n",
    "\n",
    "Nous commençons par créer quelques méthodes pour la simulation d'événements en temps réel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}\n",
    "\n",
    "def send_movie_click(USER_ID, ITEM_ID, EVENT_TYPE):\n",
    "    \"\"\"\n",
    "    Simulates a click as an envent\n",
    "    to send an event to Amazon Personalize's Event Tracker\n",
    "    \"\"\"\n",
    "    # Configure Session\n",
    "    try:\n",
    "        session_ID = session_dict[str(USER_ID)]\n",
    "    except:\n",
    "        session_dict[str(USER_ID)] = str(uuid.uuid1())\n",
    "        session_ID = session_dict[str(USER_ID)]\n",
    "        \n",
    "    # Configure Properties:\n",
    "    event = {\n",
    "    \"itemId\": str(ITEM_ID),\n",
    "    }\n",
    "    event_json = json.dumps(event)\n",
    "        \n",
    "    # Make Call\n",
    "    \n",
    "    personalize_events.put_events(\n",
    "    trackingId = TRACKING_ID,\n",
    "    userId= str(USER_ID),\n",
    "    sessionId = session_ID,\n",
    "    eventList = [{\n",
    "        'sentAt': int(time.time()),\n",
    "        'eventType': str(EVENT_TYPE),\n",
    "        'properties': event_json\n",
    "        }]\n",
    "    )\n",
    "\n",
    "def get_new_recommendations_df_users_real_time(recommendations_df, user_id, item_id, event_type):\n",
    "    # Get the artist name (header of column)\n",
    "    movie_name = get_movie_by_id(item_id)\n",
    "    # Interact with different movies\n",
    "    print('sending event ' + event_type + ' for ' + get_movie_by_id(item_id))\n",
    "    send_movie_click(USER_ID=user_id, ITEM_ID=item_id, EVENT_TYPE=event_type)\n",
    "    # Get the recommendations (note you should have a base recommendation DF created before)\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = userpersonalization_campaign_arn,\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        artist = get_movie_by_id(item['itemId'])\n",
    "        recommendation_list.append(artist)\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [movie_name])\n",
    "    # Add this dataframe to the old one\n",
    "    #recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "    recommendations_df = pd.concat([recommendations_df, new_rec_DF], axis=1)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À ce stade, nous n'avons pas encore généré d'événements en temps réel ; nous avons seulement configuré le code. Pour comparer les recommandations formulées avant et après les événements en temps réel, nous allons choisir un utilisateur et générer les recommandations originales pour lui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pick a user\n",
    "user_id = user\n",
    "\n",
    "# Get recommendations for the user\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = userpersonalization_campaign_arn,\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "\n",
    "# Build a new dataframe for the recommendations\n",
    "item_list = get_recommendations_response['itemList']\n",
    "recommendation_list = []\n",
    "for item in item_list:\n",
    "    artist = get_movie_by_id(item['itemId'])\n",
    "    recommendation_list.append(artist)\n",
    "user_recommendations_df = pd.DataFrame(recommendation_list, columns = [user_id])\n",
    "user_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous disposons à présent d'une liste de recommandations pour cet utilisateur avant d'avoir appliqué des événements en temps réel. Choisissons à présent 3 artistes au hasard avec lesquels nous allons simuler l'interaction de notre utilisateur et, voyons comment cela modifie les recommandations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next generate 3 random movies\n",
    "movies = items_df.sample(3).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this will take about 15 seconds to complete due to the sleeps\n",
    "for movie in movies:\n",
    "    user_recommendations_df = get_new_recommendations_df_users_real_time(user_recommendations_df, user_id, movie,'click')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons à présent examiner comment les événements de type clic ont modifié les recommandations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessus, la première colonne après l'index est constituée des recommandations par défaut de l'utilisateur issues de la personnalisation de l'utilisateur, et chaque colonne suivante comporte un en-tête de l'artiste avec lequel il a interagi par le biais d'un événement en temps réel ainsi que les recommandations à la suite de cet événement. \n",
    "\n",
    "Il est possible que le comportement ne change pas beaucoup. Cela est dû à la nature relativement limitée de ce jeu de données et à l'effet de quelques clics aléatoires. Pour mieux comprendre ce phénomène, essayez de simuler le fait de cliquer sur plusieurs films et vous devriez constater un impact notable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons à présent les filtres d'articles qui vous permettent de filtrer les articles en fonction des données d'interaction. Pour ce jeu de données, il pourrait s'agir d'un clic ou d'un visionnage en fonction des données que nous avons importées. Il pourrait aussi s'agir de n'importe quel schéma d'interaction que vous concevez (clic, taux, appréciation, lecture, achat, etc.). Pour les répertoires de VOD, vous pouvez faire passer un titre de la catégorie « Bons plans pour vous » à la catégorie « À revoir ». Les recommandations « À revoir » seront basées sur les interactions actuelles de l'utilisateur, mais ne recommanderont que les titres qui ont déjà été regardés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df_events = pd.DataFrame()\n",
    "for filter_arn in interaction_filter_arns:\n",
    "    recommendations_df_events = get_new_recommendations_df_by_filter(recommendations_df_events, user, filter_arn)\n",
    "    \n",
    "recommendations_df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent soumettre un événement de visionnage pour 4 recommandations non visionnées, ce qui simulerait le visionnage de 4 films. Dans une application de VOD, vous pouvez choisir de soumettre un événement après que l'utilisateur a regardé une bonne partie (plus de 75 %) du contenu. Si vous soumettez l'évènement lorsque l'utilisateur a regardé 100 % du contenu, les utilisateurs à court de crédit avant 100 % n'auront pas accès à l'évènement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get the recommendations\n",
    "top_unwatched_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = userpersonalization_campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    filterArn = filter_arn,\n",
    "    numResults=4)\n",
    "item_list = top_unwatched_recommendations_response['itemList']\n",
    "for item in item_list:\n",
    "    print('sending event watch for ' + get_movie_by_id(item['itemId']))\n",
    "    send_movie_click(USER_ID=user_id, ITEM_ID=item['itemId'], EVENT_TYPE='watch')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons à présent consulter les filtres d'événements pour voir les recommandations mises à jour, qu'elles soient suivies ou non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df_events = pd.DataFrame()\n",
    "for filter_arn in interaction_filter_arns:\n",
    "    recommendations_df_events = get_new_recommendations_df_by_filter(recommendations_df_events, user, filter_arn)\n",
    "    \n",
    "recommendations_df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classement personnalisé\n",
    "\n",
    "Le cas d'utilisation principal du classement personnalisé consiste à traiter une collection d'articles et à les présenter par ordre de priorité ou d'intérêt probable pour un utilisateur. Pour une application de VOD, vous souhaitez présenter de manière dynamique un répertoire personnalisé (répertoire, rail, carrousel) en fonction de certaines informations (réalisateur, lieu, franchise de super-héros, période du film, etc.). Il se peut que ces informations ne figurent pas dans vos métadonnées, ce qui signifie qu'un filtre de métadonnées des articles ne fonctionnera pas. Cependant, vous pouvez disposer de ces informations dans votre système pour générer la liste des articles. \n",
    "\n",
    "Pour le démontrer, nous allons utiliser le même utilisateur que précédemment et une collection aléatoire d'articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_user = user\n",
    "rerank_items = items_df.sample(25).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez maintenant un tableau de données qui montre les données d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_list = []\n",
    "for item in rerank_items:\n",
    "    movie = get_movie_by_id(item)\n",
    "    rerank_list.append(movie)\n",
    "rerank_df = pd.DataFrame(rerank_list, columns = ['Un-Ranked'])\n",
    "rerank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancez ensuite l'appel d'API de classement personnalisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user to string:\n",
    "user_id = str(rerank_user)\n",
    "rerank_item_list = []\n",
    "for item in rerank_items:\n",
    "    rerank_item_list.append(str(item))\n",
    "    \n",
    "# Get recommended reranking\n",
    "get_recommendations_response_rerank = personalize_runtime.get_personalized_ranking(\n",
    "        campaignArn = rerank_campaign_arn,\n",
    "        userId = user_id,\n",
    "        inputList = rerank_item_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez à présent les articles reclassés dans une deuxième colonne du tableau de données original, pour une comparaison parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_list = []\n",
    "item_list = get_recommendations_response_rerank['personalizedRanking']\n",
    "for item in item_list:\n",
    "    movie = get_movie_by_id(item['itemId'])\n",
    "    ranked_list.append(movie)\n",
    "ranked_df = pd.DataFrame(ranked_list, columns = ['Re-Ranked'])\n",
    "rerank_df = pd.concat([rerank_df, ranked_df], axis=1)\n",
    "rerank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez constater ci-dessus comment chaque entrée a été réorganisée en fonction de la compréhension du modèle par l'utilisateur. C'est une tâche courante lorsque vous avez une collection d'articles à présenter à un utilisateur, une liste de promotions par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations par lots<a class=\"anchor\" id=\"batch\"></a>\n",
    "[Retour au début](#top)\n",
    "\n",
    "Dans de nombreux cas, vous pouvez souhaiter disposer d'un plus grand jeu de données de recommandations exportées. Récemment, Amazon Personalize a introduit les recommandations par lots comme moyen d'exporter une collection de recommandations vers S3. Dans cet exemple, nous allons étudier la manière de procéder pour la solution HRNN. Pour en savoir plus sur les recommandations par lots, veuillez vous reporter à la [documentation](https://docs.aws.amazon.com/personalize/latest/dg/getting-recommendations.html#recommendations-batch). Cette fonction s'applique à toutes les recettes, mais le format de sortie varie.\n",
    "\n",
    "Une implémentation simple se présente comme suit :\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "personalize_rec = boto3.client(service_name='personalize')\n",
    "\n",
    "personalize_rec.create_batch_inference_job (\n",
    "    solutionVersionArn = \"ARN de la version de la solution,\"\n",
    "    jobName = \"Nom de la tâche du lot\",\n",
    "    roleArn = \"ARN du rôle IAM\",\n",
    "    jobInput = \n",
    "       {\"s3DataSource\": {\"path\": S3 input path}},\n",
    "    jobOutput = \n",
    "       {\"s3DataDestination\": {\"path\":S3 output path\"}}\n",
    ")\n",
    "```\n",
    "\n",
    "L'importation du kit SDK, l'ARN de la version de la solution et les ARN de rôle ont tous été définis. Il ne reste plus qu'à définir une entrée, une sortie et un nom de tâche.\n",
    "\n",
    "Commençant par l'entrée pour HRNN, qui se présente comme suit :\n",
    "\n",
    "\n",
    "```JSON\n",
    "{\"userId\": \"4638\"}\n",
    "{\"userId\": \"663\"}\n",
    "{\"userId\": \"3384\"}\n",
    "```\n",
    "\n",
    "Le résultat devrait ressembler à ce qui suit :\n",
    "\n",
    "```JSON\n",
    "{\"input\":{\"userId\":\"4638\"}, \"output\": {\"recommendedItems\": [\"296\", \"1\", \"260\", \"318\"]}}\n",
    "{\"input\":{\"userId\":\"663\"}, \"output\": {\"recommendedItems\": [\"1393\", \"3793\", \"2701\", \"3826\"]}}\n",
    "{\"input\":{\"userId\":\"3384\"}, \"output\": {\"recommendedItems\": [\"8368\", \"5989\", \"40815\", \"48780\"]}}\n",
    "```\n",
    "\n",
    "La sortie est un fichier JSON Lines. Il est constitué d'objets JSON individuels, un par ligne. Nous devrons donc fournir un effort supplémentaire par la suite pour digérer les résultats dans ce format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du fichier d'entrée\n",
    "\n",
    "Lorsque vous utilisez la fonction de traitement par lots, vous indiquez les utilisateurs pour lesquels vous souhaitez recevoir des recommandations lorsque la tâche est terminée. La cellule ci-dessous va à nouveau sélectionner quelques utilisateurs au hasard, puis créer le fichier et le sauvegarder sur le disque. À partir de là, vous le chargerez sur S3 pour l'utiliser plus tard dans l'appel d'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the same users from before\n",
    "users\n",
    "# Write the file to disk\n",
    "json_input_filename = \"json_input.json\"\n",
    "with open(data_dir + \"/\" + json_input_filename, 'w') as json_input:\n",
    "    for user_id in users:\n",
    "        json_input.write('{\"userId\": \"' + str(user_id) + '\"}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase the input file:\n",
    "!cat $data_dir\"/\"$json_input_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez le fichier vers S3 et enregistrez le chemin d'accès comme variable pour plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to S3\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(json_input_filename).upload_file(data_dir+\"/\"+json_input_filename)\n",
    "s3_input_path = \"s3://\" + bucket_name + \"/\" + json_input_filename\n",
    "print(s3_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les recommandations par lots lisent l'entrée du fichier que nous avons chargé sur S3. De la même manière, les recommandations par lots enregistreront le résultat dans un fichier dans S3. Nous définissons donc le chemin de sortie où les résultats doivent être enregistrés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path\n",
    "s3_output_path = \"s3://\" + bucket_name + \"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, exécutez simplement l'appel pour lancer l'exportation par lots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchInferenceJobArn = personalize.create_batch_inference_job (\n",
    "    solutionVersionArn = userpersonalization_solution_version_arn,\n",
    "    jobName = \"VOD-POC-Batch-Inference-Job-UserPersonalization_\" + str(round(time.time()*1000)),\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
    ")\n",
    "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécutez la boucle while ci-dessous pour suivre le statut de l'appel de recommandation par lot. Cette opération peut prendre environ 30 minutes, car Personalize doit mettre en place l'infrastructure pour effectuer cette tâche. Nous testons la fonction avec un jeu de données de seulement 3 utilisateurs, ce qui n'est pas une utilisation efficace de ce mécanisme. Normalement, vous n'utiliserez cette fonction que pour le traitement en masse, auquel cas les gains d'efficacité deviendront évidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "export_name = json_input_filename + \".out\"\n",
    "s3.download_file(bucket_name, export_name, data_dir+\"/\"+export_name)\n",
    "\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "with open(data_dir+\"/\"+export_name) as json_file:\n",
    "    # Get the first line and parse it\n",
    "    line = json.loads(json_file.readline())\n",
    "    # Do the same for the other lines\n",
    "    while line:\n",
    "        # extract the user ID \n",
    "        col_header = \"User: \" + line['input']['userId']\n",
    "        # Create a list for all the artists\n",
    "        recommendation_list = []\n",
    "        # Add all the entries\n",
    "        for item in line['output']['recommendedItems']:\n",
    "            movie = get_movie_by_id(item)\n",
    "            recommendation_list.append(movie)\n",
    "        if 'bulk_recommendations_df' in locals():\n",
    "            new_rec_DF = pd.DataFrame(recommendation_list, columns = [col_header])\n",
    "            bulk_recommendations_df = bulk_recommendations_df.join(new_rec_DF)\n",
    "        else:\n",
    "            bulk_recommendations_df = pd.DataFrame(recommendation_list, columns=[col_header])\n",
    "        try:\n",
    "            line = json.loads(json_file.readline())\n",
    "        except:\n",
    "            line = None\n",
    "bulk_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récapitulatif <a class=\"anchor\" id=\"wrapup\"></a>\n",
    "[Retour au début](#top)\n",
    "\n",
    "Vous disposez désormais d'un ensemble de modèles parfaitement opérationnels pour aborder divers scénarios de recommandation et de personnalisation, ainsi que des compétences nécessaires pour manipuler les données des clients afin de mieux les intégrer au service. Vous saurez comment procéder par le biais de l'API et en exploitant des outils de science des données open source.\n",
    "\n",
    "Utilisez ces bloc-notes comme guide pour démarrer avec vos clients pour les POC. Si vous trouvez des composants manquants ou si vous découvrez de nouvelles approches, faites une demande d'extraction et fournissez tout composant supplémentaire utile qui pourrait manquer dans cette collection.\n",
    "\n",
    "Vous devrez vous assurer de supprimer toutes les ressources déployées dans le cadre de cette POC. Nous avons fourni un bloc-notes distinct qui vous montre comment identifier et supprimer les ressources dans `06_Clean_Up_Resources.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store event_tracker_arn\n",
    "%store batchInferenceJobArn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
