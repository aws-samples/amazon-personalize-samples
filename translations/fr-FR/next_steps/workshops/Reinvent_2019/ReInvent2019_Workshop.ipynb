{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier ReInvent 2019 Amazon Personalize\n",
    "\n",
    "![MainDiagram](static/imgs/image.png)\n",
    "\n",
    "## Ordre du jour\n",
    "\n",
    "De manière générale, l'utilisation d'Amazon Personalize suit les étapes du schéma ci-dessous :\n",
    "\n",
    "![FlowDiagram](static/imgs/personalize_process.png)\n",
    "\n",
    "Le protocole à suivre est le suivant :\n",
    "\n",
    "1. Importations et configuration\n",
    "1. Préparation de vos données\n",
    "1. Importation de vos données\n",
    "1. Sélection d'une recette\n",
    "1. Entraînement d'une solution\n",
    "1. Déploiement d'une campagne\n",
    "1. Obtention de recommandations\n",
    "1. Interactions en temps réel\n",
    "1. Conclusion\n",
    "1. Bonus : Exportation en masse des recommandations\n",
    "\n",
    "Dans chacune de ces étapes, vous verrez et exécuterez des extraits de code écrits en Python à l'aide de notre kit SDK Boto3. Ces extraits peuvent être modifiés pour devenir des composants de votre intégration de production avec Personalize. \n",
    "\n",
    "Vous trouverez dans ce bloc-notes les étapes de la création d'un modèle de recommandation de films adapté à des utilisateurs spécifiques, l'objectif étant de recommander des films en fonction de l'historique des interactions positives de ces utilisateurs avec les films.\n",
    "\n",
    "Les données sont fournies par le [projet MovieLens](https://movielens.org). Vous pourrez en savoir plus à ce sujet plus tard si vous êtes intéressé.\n",
    "\n",
    "Le contenu ci-dessous a été rédigé pour vous guider dans le processus au cours d'une séance d'atelier. Vous pouvez déployer ultérieurement le modèle CloudFormation que vous avez trouvé sur GitHub sur votre propre compte et vous pouvez parcourir les bloc-notes 1 à 3 pour refaire le même exercice. En outre, vous pouvez mettre à jour le contenu des cellules pour prendre en compte vos propres données. Il s'agit d'un moyen efficace de créer un modèle de recommandation personnalisé pour votre cas d'utilisation.\n",
    "\n",
    "## Comment utiliser le bloc-notes\n",
    "\n",
    "Le code est décomposé en cellules comme celle ci-dessous. Vous trouverez en haut de cette page un bouton `Run` triangulaire sur lequel vous pouvez cliquer pour valider chaque cellule et passer à la suivante. Vous pouvez aussi appuyer sur `Shift` + `Enter` ou `Shift` + `Return` (utilisateurs Mac) lorsque vous êtes dans la cellule pour la valider et passer à la suivante.\n",
    "\n",
    "\n",
    "Lorsqu'une cellule est en cours d'exécution, vous remarquerez une ligne sur le coté affichant une `*` pendant que la cellule est opérationnelle ou elle se mettra à jour sous forme de nombre pour indiquer la dernière cellule qui a terminé l'exécution après avoir achevé l'exécution de tous les codes dans une cellule.\n",
    "\n",
    "\n",
    "Il suffit de suivre les instructions ci-dessous et d'exécuter les cellules pour commencer avec Amazon Personalize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations et configuration \n",
    "\n",
    "Python est livré avec une grande collection de bibliothèques. Nous devons les importer ainsi que celles qui sont installées pour nous aider comme boto3 (le kit SDK AWS) et Pandas/Numpy qui sont des outils de base de la science des données. La cellule ci-dessous les importera pour les utiliser ici. Elle mettra également à jour la bibliothèque boto3 vers la dernière version. Vous pourriez voir apparaître un avertissement (texte jaune) ou une erreur (texte rouge). Ne vous inquiétez pas. Continuez simplement à exécuter la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update boto3\n",
    "!pip install --upgrade boto3\n",
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, vous devez vérifier que votre environnement peut communiquer avec Amazon Personalize. Les lignes ci-dessous servent à cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "personalize_events = boto3.client(service_name='personalize-events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dernière étape consiste à déterminer la région dans laquelle vous organisez cet atelier. La cellule ci-dessous le fera et l'assignera à la variable `region`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de vos données\n",
    "\n",
    "Tout d'abord, vous aurez besoin d'une collection de points de données où les utilisateurs ont interagi avec le contenu d'une manière ou d'une autre. Amazon Personalize part du principe que si une interaction est enregistrée, elle est positive. Vous verrez plus tard comment nous utilisons cet aspect. \n",
    "\n",
    "La cellule ci-dessous téléchargera les données dont vous avez besoin, extraira le contenu d'un fichier Zip, puis en affichera une infime partie sur votre écran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'], engine='python')\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir, les données contiennent un UserID, un ItemID, un Rating et un Timestamp.\n",
    "\n",
    "Nous n'avons pas besoin de la colonne `Rating`. Elle sera donc supprimée avant de sauvegarder le fichier.\n",
    "\n",
    "Une fois les données préparées, vous les enregistrerez localement dans un fichier CSV avec la dernière ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "filename = \"movie-lens-ml-100k-prepared.csv\"\n",
    "data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de pouvoir télécharger les données dans S3, vous devez créer un compartiment, la cellule ci-dessous s'en chargera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(region)\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"reinventpersonalizeworkshop\"\n",
    "print(bucket_name)\n",
    "if region != \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "else:\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez à présent télécharger le fichier sur S3 et il sera prêt à être importé dans Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation de vos données\n",
    "\n",
    "Les étapes à suivre pour importer vos données sont les suivantes :\n",
    "\n",
    "1. Créez un groupe de jeux de données.\n",
    "1. Identifiez le schéma de votre jeux de données.\n",
    "1. Créez un ensemble de données en utilisant votre schéma.\n",
    "1. Exécutez un ImportJob pour charger les données à utiliser avec Personalize.\n",
    "\n",
    "\n",
    "Dans Amazon Personalize, un groupe de jeux de données est la façon dont vos informations sont isolées de toute autre expérience. Aucune information n'est partagée entre ces groupes. Un groupe de jeux de données peut contenir vos données d'interaction, vos métadonnées sur les articles, vos métadonnées sur les utilisateurs, vos dispositifs de suivi des événements, vos solutions et vos campagnes. Pour en savoir plus à ce sujet : https://docs.aws.amazon.com/personalize/latest/dg/API_DatasetGroup.html \n",
    "\n",
    "Commencez par créer un groupe de jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un groupe de jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-RI-demo\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boucle de création d'un groupe de jeux de données\n",
    "\n",
    "La création d'un DatasetGroup prend quelques secondes. La cellule ci-dessous sera donc interrogée jusqu'à ce que le DatasetGroup soit actif et que vous puissiez poursuivre l'atelier. Une fois que `ACTIVE` s'affiche, passez à l'étape `Create Schema`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un schéma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez à présent déterminer le schéma de votre jeu de données. Compte tenu de la limite de temps, vous n'utiliserez dans cet atelier que les données relatives à l'interaction utilisateur-article, ou données d'interaction en abrégé. La cellule ci-dessous contient les articles exigés pour ce jeu de données et correspond à la structure du CSV que vous avez téléchargé précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous créera un schéma dans Amazon Personalize qui peut être connecté à un jeu de données ; c'est ainsi que Personalize interprète le contenu de votre fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-ri-demo-schema\",\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un jeu de données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, créez le jeu de données pour les interactions, attribuez-lui le schéma fourni et affectez-le au groupe de données que vous avez créé précédemment avec ce code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-ri-interactions\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn\n",
    ")\n",
    "\n",
    "dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attacher une politique au compartiment S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de pouvoir exécuter la tâche d'importation de vos données, vous devrez joindre une politique de compartiment à votre compartiment S3 pour permettre à Personalize de communiquer avec lui, ainsi qu'un rôle IAM pour le service à utiliser dans ce compte AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que les changements IAM dans la cellule ci-dessous ne prennent que quelques secondes pour être confirmés. Cette section prendra donc une minute pour être terminée. Exécutez ensuite la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer un rôle Personalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRoleRIDemo\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, vous êtes prêt à importer les données dans Personalize. La première cellule ci-dessous lancera le processus et la seconde contient une boucle while qui interrogera le service pour déterminer quand le processus d'importation sera terminé. \n",
    "\n",
    "Au cours de cet atelier, vous allez importer un jeu de données relativement petit et cette opération peut sembler longue pour un si petit fichier. Dans ce cas, la priorité est donnée au provisionnement en ressources dédiées qui exécuteront réellement la tâche. Personalize est ainsi en mesure d'assurer la conformité HIPAA, par exemple. De plus, ce n'est pas parce que vos fichiers sont plus volumineux que l'importation est extrêmement longue : une fois les ressources en place, l'importation est assez rapide.\n",
    "\n",
    "Le processus d'importation peut prendre jusqu'à 20 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une tâche d'importation de jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-ri-import\",\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boucle d'importation de jeux de données\n",
    "\n",
    "Le remplissage de la cellule ci-dessous prendra un peu plus de temps. Il s'agit d'un sondage pour savoir quand votre jeu de données a été entièrement importé dans Personalize. Cette opération devrait prendre environ 20 minutes. La plus grosse partie du temps est consacrée au provisionnement de l'infrastructure en coulisse. Autrement dit, l'importation de fichiers beaucoup plus volumineux ne prend pas beaucoup plus de temps dans la plupart des cas.\n",
    "\n",
    "Exécutez la cellule ci-dessous, puis passez à autre chose lorsqu'elle atteint un statut `ACTIVE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection d'une recette\n",
    "\n",
    "Avec Personalize, les algorithmes disponibles sont appelés des recettes. Le code ci-dessous vous en donne la liste complète. Ils présentent chacun des divers cas d'utilisation et vous trouverez des informations détaillées ici : https://docs.aws.amazon.com/personalize/latest/dg/working-with-predefined-recipes.html.\n",
    "\n",
    "Dans cet atelier, vous utiliserez HRNN (Hierarchical Recurrent Neural Network) en citant les documents :\n",
    "\n",
    "```\n",
    "Le HRRN est un réseau neuronal récurrent hiérarchique, capable de modéliser les interactions utilisateur-article sur une période donnée. Utilisez la recette HRNN lorsque le comportement de l'utilisateur change au fil du temps, un phénomène que l'on appelle problème de l'intention évolutive.\n",
    "\n",
    "Pour entraîner un modèle, HRNN utilise le jeu de données des interactions d'un groupe de jeu de données. Un groupe de jeux de données est un ensemble de jeux de données apparentés qui peuvent inclure les jeux de données Utilisateurs, Articles et Interactions.\n",
    "```\n",
    "\n",
    "Vous trouverez ici un document qui l'explique plus en détail en relation avec les recommandations : https://openreview.net/pdf?id=ByzxsrrkJ4. \n",
    "\n",
    "\n",
    "Il sert ici d'exemple de système de recommandation construit à l'aide de réseaux neuronaux profonds et peut être entraîné en utilisant uniquement nos données d'interactions. Il s'agit là d'un excellent point de départ pour mener vos propres expériences par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous sélectionne la recette `HRNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement d'une solution\n",
    "\n",
    "Dans Amazon Personalize, un modèle entraîné sur des données client s'appelle une solution. Ces modèles sont classés par version et vous devez donc d'abord créer une solution, puis une version de solution. Les versions sont utilisées pour suivre l'amélioration du modèle sur une période donnée, en fonction des nouvelles données disponibles. \n",
    "\n",
    "La création d'une solution en soi est presque instantanée, mais l'entraînement à la création d'une version peut prendre un peu de temps. Il s'agit généralement de la période d'attente la plus longue de la procédure. Si vous vous livrez à cette expérience en dehors d'un atelier, c'est le moment idéal pour lire vos courriels, prendre un café, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-ri-soln-hrnn\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une version de solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer la boucle de la version de la solution\n",
    "\n",
    "L'entraînement d'un modèle peut prendre un peu de temps. Il faut souvent compter au moins 20 minutes. Exécutez la cellule ci-dessous, en attendant à nouveau qu'elle passe à un état `ACTIVE` avant de passer à la prochaine étape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Training Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Training Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenir les métriques sur la version de la solution\n",
    "\n",
    "Maintenant que votre solution et sa version sont en place, vous pouvez obtenir les métriques qui vous permettront de juger de ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer et attendre la campagne\n",
    "\n",
    "Maintenant que vous avez une version de la solution opérationnelle, vous devez créer une campagne pour l'utiliser avec vos applications. Une campagne est simplement une copie hébergée de votre modèle. Encore une fois, il faudra attendre un peu pour qu'après l'exécution, vous puissiez faire une petite pause pendant que l'infrastructure est mise en place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer une campagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-ri-camp\",\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attendre que la campagne ait le statut ACTIF\n",
    "\n",
    "#### Créer une boucle de campagne\n",
    "\n",
    "Dans cette section, Personalize déploie votre modèle, ce qui prend quelques minutes. Exécutez la cellule ci-dessous pour interroger à nouveau jusqu'à ce que la tâche soit terminée. Cette opération devrait prendre 10 à 15 minutes. Une fois que la cellule a atteint l'état `ACTIVE`, continuez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Deploying Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Deploying Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir des exemples de recommandations\n",
    "\n",
    "Une fois la campagne active, vous êtes prêt à recevoir des recommandations. Tout d'abord, nous devons sélectionner un utilisateur aléatoire à partir de la collection. Ensuite, nous créerons quelques fonctions d'aide pour obtenir des informations sur les films à afficher pour les recommandations au lieu de simples ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a random user:\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "print(\"USER: {}\".format(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], encoding='latin-1', names=['ITEM_ID', 'TITLE'], index_col='ITEM_ID')\n",
    "\n",
    "def get_movie_title(movie_id):\n",
    "    \"\"\"\n",
    "    Takes in an ID, returns a title\n",
    "    \"\"\"\n",
    "    movie_id = int(movie_id)-1\n",
    "    return items.iloc[movie_id]['TITLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appeler GetRecommendations\n",
    "\n",
    "Le code ci-dessous obtient des recommandations pour l'utilisateur sélectionné au hasard. Il place ensuite les recommandations dans un cadre de données et les affiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = get_movie_title(item['itemId'])\n",
    "    recommendation_list.append(title)\n",
    "    \n",
    "recommendations_df = pd.DataFrame(recommendation_list, columns = ['Original Recommendations'])\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un outil de suivi des événements\n",
    "\n",
    "Pour que votre système de recommandation puisse répondre à des événements en temps réel, vous avez besoin d'un outil de suivi des événements. Le code ci-dessous en génère un et peut être utilisé pour la suite de cet atelier. N'hésitez pas à remplacer son nom par un nom plus descriptif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = personalize.create_event_tracker(\n",
    "    name='MovieClickTrackerRI',\n",
    "    datasetGroupArn=dataset_group_arn\n",
    ")\n",
    "print(response['eventTrackerArn'])\n",
    "print(response['trackingId'])\n",
    "TRACKING_ID = response['trackingId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tracker_arn = response['eventTrackerArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation du comportement des utilisateurs\n",
    "\n",
    "Les lignes ci-dessous fournissent un exemple de code qui simule un utilisateur interagissant avec un article donné. Vous obtiendrez alors des recommandations différentes de celles de départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_movie_click(USER_ID, ITEM_ID):\n",
    "    \"\"\"\n",
    "    Simulates a click as an envent\n",
    "    to send an event to Amazon Personalize's Event Tracker\n",
    "    \"\"\"\n",
    "    # Configure Session\n",
    "    try:\n",
    "        session_ID = session_dict[USER_ID]\n",
    "    except:\n",
    "        session_dict[USER_ID] = str(uuid.uuid1())\n",
    "        session_ID = session_dict[USER_ID]\n",
    "        \n",
    "    # Configure Properties:\n",
    "    event = {\n",
    "    \"itemId\": str(ITEM_ID),\n",
    "    }\n",
    "    event_json = json.dumps(event)\n",
    "        \n",
    "    # Make Call\n",
    "    personalize_events.put_events(\n",
    "    trackingId = TRACKING_ID,\n",
    "    userId= USER_ID,\n",
    "    sessionId = session_ID,\n",
    "    eventList = [{\n",
    "        'sentAt': int(time.time()),\n",
    "        'eventType': 'EVENT_TYPE',\n",
    "        'properties': event_json\n",
    "        }]\n",
    "    )\n",
    "\n",
    "def get_new_recommendations_df(recommendations_df, movie_ID):\n",
    "    # Get the title of the movie for the header of the column\n",
    "    movie_title_clicked = get_movie_title(movie_to_click)\n",
    "    # Interact with the movie\n",
    "    send_movie_click(USER_ID=str(user_id), ITEM_ID=movie_to_click)\n",
    "    # Sleep for 2 seconds\n",
    "    time.sleep(2)\n",
    "    # Get new recommendations\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = campaign_arn,\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        title = get_movie_title(item['itemId'])\n",
    "        recommendation_list.append(title)\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [movie_title_clicked])\n",
    "    # Add this dataframe to the old one\n",
    "    recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les trois cellules ci-dessous simulent l'ajout d'un film au jeu de données et affichent les résultats après chaque interaction. La première colonne correspond aux recommandations originales, les colonnes suivantes correspondent à chaque film avec lequel l'utilisateur a interagi. L'en-tête de colonne est le nom du film avec lequel l'utilisateur a interagi, puis vous pourrez voir comment les recommandations sont modifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_click = 180\n",
    "recommendations_df = get_new_recommendations_df(recommendations_df, movie_to_click)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_click = 210\n",
    "recommendations_df = get_new_recommendations_df(recommendations_df, movie_to_click)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_click = 415\n",
    "recommendations_df = get_new_recommendations_df(recommendations_df, movie_to_click)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans cet atelier, vous avez réussi à créer un groupe de jeux de données et un jeu de données basé sur les interactions. Vous avez aussi appris à entraîner un modèle de recommandation basé sur les données, à déployer une campagne pour générer des recommandations, à évaluer les recommandations initiales, à exploiter le suivi des événements en temps réel pour obtenir des recommandations encore meilleures. Vous trouverez ci-dessous des documents bonus montrant comment exporter les recommandations dans le système de gestion de l'information.  \n",
    "\n",
    "Ce contenu restera public sur GitHub et pourra être utilisé au sein de votre organisation pour construire des modèles de recommandation personnalisés. Jetez un coup d'œil aux divers autres bloc-notes à l'avenir.\n",
    "\n",
    "Merci, et bonne chance pour votre prochain projet de machine learning !\n",
    "\n",
    "VOUS TROUVEREZ CI-DESSOUS LES DOCUMENTS BONUS :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations par lots\n",
    "\n",
    "Jusqu'à présent, vous avez appris à générer des recommandations au moyen d'un appel d'API et à interagir avec des systèmes de suivi des événements. Cette approche fonctionne bien pour de nombreuses applications, mais il se peut que vous souhaitiez mettre en cache localement toutes les recommandations destinées aux utilisateurs ou même étudier les recommandations pour trouver de nouvelles idées. Pour y parvenir, Amazon Personalize prend également en charge l'exportation par lots de vos recommandations vers un fichier. Les cellules ci-dessous vous guideront dans la soumission de recommandations à un fichier dans S3 et vous afficheront ensuite son contenu. Le fichier peut également être téléchargé de S3 vers votre ordinateur local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, vous devrez créer un fichier JSON de l'utilisateur IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_IDs = ['561', '233', '579']\n",
    "\n",
    "json_input_filename = \"json_input.json\"\n",
    "with open(json_input_filename, 'w') as json_input:\n",
    "    for user_id in user_IDs:\n",
    "        json_input.write('{\"userId\": \"' + user_id + '\"}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargez à présent ce fichier sur S3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(json_input_filename).upload_file(json_input_filename)\n",
    "s3_input_path = \"s3://\" + bucket_name + \"/\" + json_input_filename\n",
    "print(s3_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le fichier d'entrée est disponible dans S3, vous devez définir l'emplacement de la sortie et créer une tâche d'inférence par lots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_path = \"s3://\" + bucket_name + \"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous crée la tâche de lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_rec = boto3.client(service_name='personalize')\n",
    "batchInferenceJobArn = personalize_rec.create_batch_inference_job (\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    jobName = \"RI-Workshop-Batch-Inference-Job\",\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
    ")\n",
    "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante procède à l'interrogation jusqu'à ce que l'exportation soit terminée. Cette boucle d'attente est la dernière de l'atelier ! Cette dernière va à nouveau interroger jusqu'à ce qu'elle indique l'état `ACTIVE`. Vous pouvez continuer une fois que cet état est atteint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize_rec.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les données correctement exportées, récupérez le fichier et analysez-le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "export_name = json_input_filename + \".out\"\n",
    "s3.download_file(bucket_name, export_name, export_name)\n",
    "\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "with open(export_name) as json_file:\n",
    "    # Get the first line and parse it\n",
    "    line = json.loads(json_file.readline())\n",
    "    # Do the same for the other lines\n",
    "    while line:\n",
    "        # extract the user ID \n",
    "        col_header = \"User: \" + line['input']['userId']\n",
    "        # Create a list for all the movies\n",
    "        recommendation_list = []\n",
    "        # Add all the entries\n",
    "        for item in line['output']['recommendedItems']:\n",
    "            title = get_movie_title(item)\n",
    "            recommendation_list.append(title)\n",
    "        if 'bulk_recommendations_df' in locals():\n",
    "            new_rec_DF = pd.DataFrame(recommendation_list, columns = [col_header])\n",
    "            bulk_recommendations_df = bulk_recommendations_df.join(new_rec_DF)\n",
    "        else:\n",
    "            bulk_recommendations_df = pd.DataFrame(recommendation_list, columns=[col_header])\n",
    "        try:\n",
    "            line = json.loads(json_file.readline())\n",
    "        except:\n",
    "            line = None\n",
    "bulk_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessus, vous pouvez voir les différentes recommandations pour les utilisateurs fournies. Dans un scénario réel, la liste des utilisateurs pourrait être l'ensemble de votre base d'utilisateurs, vous permettant ainsi de référencer et de comparer rapidement les résultats entre eux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus supplémentaire : Nettoyer\n",
    "\n",
    "Les cellules ci-dessous sont absolument facultatives si vous utilisez Event Engine, dans la mesure où votre compte a été supprimé après l'atelier. Si vous souhaitez l'utiliser plus tard dans votre propre compte, les cellules ci-dessous supprimeront les ressources créées pour éviter des frais supplémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the campaign:\n",
    "personalize.delete_campaign(campaignArn=campaign_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the solution\n",
    "personalize.delete_solution(solutionArn=solution_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the event tracker\n",
    "personalize.delete_event_tracker(eventTrackerArn=event_tracker_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the interaction dataset\n",
    "personalize.delete_dataset(datasetArn=dataset_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the event dataset\n",
    "event_interactions_dataset_arn = dataset_arn\n",
    "event_interactions_dataset_arn = event_interactions_dataset_arn.replace(\"INTERACTIONS\", \"EVENT_INTERACTIONS\")\n",
    "personalize.delete_dataset(datasetArn=event_interactions_dataset_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the schema\n",
    "personalize.delete_schema(schemaArn=schema_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the Dataset Group\n",
    "personalize.delete_dataset_group(datasetGroupArn=dataset_group_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the S3 Bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.objects.all().delete()\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the S3 Bucket\n",
    "bucket.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM policies should also be removed\n",
    "iam = boto3.client(\"iam\")\n",
    "iam.detach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\", RoleName=role_name)\n",
    "iam.detach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\",RoleName=role_name)\n",
    "\n",
    "iam.delete_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dernière étape\n",
    "\n",
    "Après avoir supprimé toutes les ressources, vous pouvez fermer cette fenêtre et retourner à la page github sur laquelle vous vous trouviez. Au bas du fichier Readme se trouvent des étapes pour supprimer la pile CloudFormation que vous avez créée précédemment. Une fois cette étape franchie, vous avez terminé l'atelier à 100 %.\n",
    "\n",
    "Félicitations !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}