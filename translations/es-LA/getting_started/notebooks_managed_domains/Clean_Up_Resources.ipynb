{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c8df32",
   "metadata": {},
   "source": [
    "# Recursos de limpieza\n",
    "Este cuaderno demuestra cómo limpiar todos los recursos creados en el cuaderno anterior por medio de la carga de nombres de variables guardados. \n",
    "\n",
    "(!) Si creó recursos por medio de varios cuadernos y tiene varios grupos de conjuntos de datos, ejecute la celda que comienza `# store for cleanup` al final del cuaderno e, inmediatamente después, ejecute este cuaderno para cada uno de ellos (si creó dos grupos de conjuntos de datos, deberá ejecutar este cuaderno dos veces). Este código solo elimina los recursos especificados en `# store for cleanup` y, si utilizó varios cuadernos, los valores guardados corresponderán al último cuaderno que haya ejecutado.\n",
    "\n",
    "Este cuaderno emplea las funciones que se definen a continuación, con el objetivo de iterar a través de los recursos dentro de un grupo de conjunto de datos. \n",
    "\n",
    "Puede utilizar este cuaderno para eliminar los recursos de Amazon Personalize. Los ARN de los recursos se definen en el cuaderno anterior o puede ingresarlos de forma manual abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you cannot/do not want to use \"%store -r\" to load the resources to delete, \n",
    "# you can uncomment the code bellow and enter them manually\n",
    "\n",
    "# dataset_group_arn='XXXXX'\n",
    "# role_name='XXXXX'\n",
    "# region='XXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf2a20a",
   "metadata": {},
   "source": [
    "Imprima los recursos que se eliminarán. Compruebe que estos son los recursos que desea eliminar. \n",
    "Esta operación no puede deshacerse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('dataset_group_arn:', dataset_group_arn)\n",
    "print ('role_name:', role_name)\n",
    "print ('region:', region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_arns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import logging\n",
    "import botocore\n",
    "import boto3\n",
    "import time\n",
    "from packaging import version\n",
    "from time import sleep\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "personalize = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _delete_event_trackers(dataset_group_arn):\n",
    "    event_tracker_arns = []\n",
    "\n",
    "    event_trackers_paginator = personalize.get_paginator('list_event_trackers')\n",
    "    for event_tracker_page in event_trackers_paginator.paginate(datasetGroupArn = dataset_group_arn):\n",
    "        for event_tracker in event_tracker_page['eventTrackers']:\n",
    "            if event_tracker['status'] in [ 'ACTIVE', 'CREATE FAILED' ]:\n",
    "                logger.info('Deleting event tracker {}'.format(event_tracker['eventTrackerArn']))\n",
    "                personalize.delete_event_tracker(eventTrackerArn = event_tracker['eventTrackerArn'])\n",
    "            elif event_tracker['status'].startswith('DELETE'):\n",
    "                logger.warning('Event tracker {} is already being deleted so will wait for delete to complete'.format(event_tracker['eventTrackerArn']))\n",
    "            else:\n",
    "                raise Exception('Solution {} has a status of {} so cannot be deleted'.format(event_tracker['eventTrackerArn'], event_tracker['status']))\n",
    "\n",
    "            event_tracker_arns.append(event_tracker['eventTrackerArn'])\n",
    "\n",
    "    max_time = time.time() + 30*60 # 30 mins\n",
    "    while time.time() < max_time:\n",
    "        for event_tracker_arn in event_tracker_arns:\n",
    "            try:\n",
    "                describe_response = personalize.describe_event_tracker(eventTrackerArn = event_tracker_arn)\n",
    "                logger.debug('Event tracker {} status is {}'.format(event_tracker_arn, describe_response['eventTracker']['status']))\n",
    "            except ClientError as e:\n",
    "                error_code = e.response['Error']['Code']\n",
    "                if error_code == 'ResourceNotFoundException':\n",
    "                    event_tracker_arns.remove(event_tracker_arn)\n",
    "\n",
    "        if len(event_tracker_arns) == 0:\n",
    "            logger.info('All event trackers have been deleted or none exist for dataset group')\n",
    "            break\n",
    "        else:\n",
    "            logger.info('Waiting for {} event tracker(s) to be deleted'.format(len(event_tracker_arns)))\n",
    "            time.sleep(20)\n",
    "\n",
    "    if len(event_tracker_arns) > 0:\n",
    "        raise Exception('Timed out waiting for all event trackers to be deleted')\n",
    "\n",
    "def _delete_filters(dataset_group_arn):\n",
    "    filter_arns = []\n",
    "\n",
    "    filters_response = personalize.list_filters(datasetGroupArn = dataset_group_arn, maxResults = 100)\n",
    "    for filter in filters_response['Filters']:\n",
    "        logger.info('Deleting filter ' + filter['filterArn'])\n",
    "        personalize.delete_filter(filterArn = filter['filterArn'])\n",
    "        filter_arns.append(filter['filterArn'])\n",
    "\n",
    "    max_time = time.time() + 30*60 # 30 mins\n",
    "    while time.time() < max_time:\n",
    "        for filter_arn in filter_arns:\n",
    "            try:\n",
    "                describe_response = personalize.describe_filter(filterArn = filter_arn)\n",
    "                logger.debug('Filter {} status is {}'.format(filter_arn, describe_response['filter']['status']))\n",
    "            except ClientError as e:\n",
    "                error_code = e.response['Error']['Code']\n",
    "                if error_code == 'ResourceNotFoundException':\n",
    "                    filter_arns.remove(filter_arn)\n",
    "\n",
    "        if len(filter_arns) == 0:\n",
    "            logger.info('All filters have been deleted or none exist for dataset group')\n",
    "            break\n",
    "        else:\n",
    "            logger.info('Waiting for {} filter(s) to be deleted'.format(len(filter_arns)))\n",
    "            time.sleep(20)\n",
    "\n",
    "    if len(filter_arns) > 0:\n",
    "        raise Exception('Timed out waiting for all filter(s) to be deleted')\n",
    "        \n",
    "def _delete_recommenders(dataset_group_arn):\n",
    "    recommender_arns = []\n",
    "    recommenders_response = personalize.list_recommenders(datasetGroupArn = dataset_group_arn, maxResults = 100)\n",
    "    for recommender in recommenders_response['recommenders']:\n",
    "        logger.info('Deleting recommender ' + recommender['recommenderArn'])\n",
    "        personalize.delete_recommender(recommenderArn = recommender['recommenderArn'])\n",
    "        recommender_arns.append(recommender['recommenderArn'])\n",
    "    max_time = time.time() + 30*60 # 30 mins\n",
    "    while time.time() < max_time:\n",
    "        for recommender_arn in recommender_arns:\n",
    "            try:\n",
    "                describe_response = personalize.describe_recommender(recommenderArn = recommender_arn)\n",
    "                logger.debug('Recommender {} status is {}'.format(recommender_arn, describe_response['recommender']['status']))\n",
    "            except ClientError as e:\n",
    "                error_code = e.response['Error']['Code']\n",
    "                if error_code == 'ResourceNotFoundException':\n",
    "                    recommender_arns.remove(recommender_arn)\n",
    "\n",
    "        if len(recommender_arns) == 0:\n",
    "            logger.info('All recommenders have been deleted or none exist for dataset group')\n",
    "            break\n",
    "        else:\n",
    "            logger.info('Waiting for {} recommender(s) to be deleted'.format(len(recommender_arns)))\n",
    "            time.sleep(20)\n",
    "\n",
    "    if len(recommender_arns) > 0:\n",
    "        raise Exception('Timed out waiting for all recommender(s) to be deleted')\n",
    "    \n",
    "\n",
    "def _delete_datasets_and_schemas(dataset_group_arn, schema_arns):\n",
    "    dataset_arns = []\n",
    "    \n",
    "    dataset_paginator = personalize.get_paginator('list_datasets')\n",
    "    for dataset_page in dataset_paginator.paginate(datasetGroupArn = dataset_group_arn):\n",
    "        for dataset in dataset_page['datasets']:\n",
    "            describe_response = personalize.describe_dataset(datasetArn = dataset['datasetArn'])\n",
    "            schema_arns.append(describe_response['dataset']['schemaArn'])\n",
    "\n",
    "            if dataset['status'] in ['ACTIVE', 'CREATE FAILED']:\n",
    "                logger.info('Deleting dataset ' + dataset['datasetArn'])\n",
    "                personalize.delete_dataset(datasetArn = dataset['datasetArn'])\n",
    "            elif dataset['status'].startswith('DELETE'):\n",
    "                logger.warning('Dataset {} is already being deleted so will wait for delete to complete'.format(dataset['datasetArn']))\n",
    "            else:\n",
    "                raise Exception('Dataset {} has a status of {} so cannot be deleted'.format(dataset['datasetArn'], dataset['status']))\n",
    "\n",
    "            dataset_arns.append(dataset['datasetArn'])\n",
    "\n",
    "    max_time = time.time() + 30*60 # 30 mins\n",
    "    while time.time() < max_time:\n",
    "        for dataset_arn in dataset_arns:\n",
    "            try:\n",
    "                describe_response = personalize.describe_dataset(datasetArn = dataset_arn)\n",
    "                logger.debug('Dataset {} status is {}'.format(dataset_arn, describe_response['dataset']['status']))\n",
    "            except ClientError as e:\n",
    "                error_code = e.response['Error']['Code']\n",
    "                if error_code == 'ResourceNotFoundException':\n",
    "                    dataset_arns.remove(dataset_arn)\n",
    "\n",
    "        if len(dataset_arns) == 0:\n",
    "            logger.info('All datasets have been deleted or none exist for dataset group')\n",
    "            break\n",
    "        else:\n",
    "            logger.info('Waiting for {} dataset(s) to be deleted'.format(len(dataset_arns)))\n",
    "            time.sleep(20)\n",
    "\n",
    "    if len(dataset_arns) > 0:\n",
    "        raise Exception('Timed out waiting for all datasets to be deleted')\n",
    "\n",
    "    for schema_arn in schema_arns:\n",
    "        try:\n",
    "            logger.info('Deleting schema ' + schema_arn)\n",
    "            personalize.delete_schema(schemaArn = schema_arn)\n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == 'ResourceInUseException':\n",
    "                logger.info('Schema {} is still in-use by another dataset (likely in another dataset group)'.format(schema_arn))\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    logger.info('All schemas used exclusively by datasets have been deleted or none exist for dataset group')\n",
    "\n",
    "def _delete_dataset_group(dataset_group_arn):\n",
    "    logger.info('Deleting dataset group ' + dataset_group_arn)\n",
    "    personalize.delete_dataset_group(datasetGroupArn = dataset_group_arn)\n",
    "\n",
    "    max_time = time.time() + 30*60 # 30 mins\n",
    "    while time.time() < max_time:\n",
    "        try:\n",
    "            describe_response = personalize.describe_dataset_group(datasetGroupArn = dataset_group_arn)\n",
    "            logger.debug('Dataset group {} status is {}'.format(dataset_group_arn, describe_response['datasetGroup']['status']))\n",
    "            break\n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == 'ResourceNotFoundException':\n",
    "                logger.info('Dataset group {} has been fully deleted'.format(dataset_group_arn))\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        logger.info('Waiting for dataset group to be deleted')\n",
    "        time.sleep(20)\n",
    "\n",
    "def delete_dataset_groups(dataset_group_arns, schema_arns, region = None):\n",
    "    global personalize\n",
    "    personalize = boto3.client(service_name = 'personalize', region_name = region)\n",
    "\n",
    "    for dataset_group_arn in dataset_group_arns:\n",
    "        logger.info('Dataset Group ARN: ' + dataset_group_arn)\n",
    "\n",
    "        # 1. Delete Recommenders\n",
    "        _delete_recommenders(dataset_group_arn)\n",
    "        \n",
    "        # 2. Delete event trackers\n",
    "        _delete_event_trackers(dataset_group_arn)\n",
    "\n",
    "        # 3. Delete filters\n",
    "        _delete_filters(dataset_group_arn)\n",
    "\n",
    "        # 4. Delete datasets and their schemas\n",
    "        _delete_datasets_and_schemas(dataset_group_arn, schema_arns)\n",
    "\n",
    "        # 5. Delete dataset group\n",
    "        _delete_dataset_group(dataset_group_arn)\n",
    "\n",
    "        logger.info(f'Dataset group {dataset_group_arn} fully deleted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset_groups([dataset_group_arn], schema_arns, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c93c0",
   "metadata": {},
   "source": [
    "## Limpiar el rol de IAM\n",
    "Para comenzar, elimine el rol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e07dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d213dd2",
   "metadata": {},
   "source": [
    "Identifique el nombre del rol que desea eliminar.\n",
    "\n",
    "No puede eliminar un rol de IAM que aún tiene políticas adjuntas. Después de que identifique el rol relevante, enumere las políticas adjuntas a ese rol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.list_attached_role_policies(\n",
    "    RoleName = role_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detaching the role policies\n",
    "iam.detach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    ")\n",
    "iam.detach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = 'arn:aws:iam::aws:policy/AmazonS3FullAccess'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9f97a",
   "metadata": {},
   "source": [
    "Por último, debería poder eliminar el rol de IAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.delete_role(\n",
    "    RoleName = role_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a7c81",
   "metadata": {},
   "source": [
    "## Eliminación del bucket de S3\n",
    "Para eliminar un bucket de S3, primero debe estar vacío. La forma más sencilla de eliminar un bucket de S3 es simplemente navegar a S3 en la consola de AWS, eliminar los objetos en el bucket y, luego, eliminar el bucket de S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d9a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
