{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendaciones por lotes mediante el algoritmo de personalización del usuario de AWS y los datos de interacción entre el usuario y los elementos <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "En este cuaderno, elegirá un conjunto de datos y lo preparará para utilizarlo con las recomendaciones por lote de Amazon Personalize.\n",
    "\n",
    "1. [Elija un conjunto de datos o un origen de datos](#source)\n",
    "1. [Prepare los datos](#prepare)\n",
    "1. [Crear grupos de conjuntos de datos y el conjunto de datos de las interacciones](#group_dataset)\n",
    "1. [Configurar un bucket de S3 y un rol de IAM](#bucket_role)\n",
    "1. [Importar los datos de las interacciones](#import)\n",
    "1. [Crear soluciones](#solutions)\n",
    "1. [Recomendaciones por lote](#batch)\n",
    "1. [Limpiar](#cleanup)\n",
    "\n",
    "## Introducción <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Por lo general, los algoritmos en Amazon Personalize (llamados recetas) buscan resolver diferentes tareas que se explican a continuación:\n",
    "\n",
    "1. **Personalización del usuario de AWS**: recomienda elementos según las interacciones previas del usuario con los elementos.\n",
    "1. **Personalized-Ranking**: toma una recopilación de elementos y, luego, los ubica en un posible orden de interés mediante un enfoque similar al de una HRNN.\n",
    "1. **SIMS (elementos similares)**: en base a un elemento, recomienda otros elementos con los que también interactúan los usuarios.\n",
    "1. **Popularity-Count**: recomienda los elementos más populares, si la HRNN o los metadatos de la HRNN no ofrecen una respuesta. Esta es la devolución predeterminada.\n",
    "\n",
    "Sin importar cuál sea el caso de uso, todos los algoritmos comparten una base de aprendizaje sobre los datos de interacción entre el usuario y los elementos, la cual se define según 3 atributos principales:\n",
    "\n",
    "1. **UserID**: el usuario que interactuó\n",
    "1. **ItemID**: el elemento con el que interactuó el usuario\n",
    "1. **Timestamp (Marca temporal)**: la hora a la que ocurrió la interacción\n",
    "\n",
    "También admitimos los tipos de eventos y valores de eventos definidos por lo siguiente:\n",
    "\n",
    "1. **Tipo de evento**: etiquetado de eventos por categoría (navegación, compra, clasificación, etc.).\n",
    "1. **Valor de evento**: valor que corresponde al tipo de evento acontecido. En términos generales, buscamos valores normalizados entre 0 y 1 entre los tipos de eventos. Por ejemplo, si existen tres fases para completar una transacción (seleccionar, agregar al carrito y comprar), entonces hay un valor de evento para cada fase, como 0.33, 0.66 y 1.0, respectivamente.\n",
    "\n",
    "Los campos para el tipo de evento y valor de evento son datos adicionales que se pueden utilizar para filtrar los datos enviados para el entrenamiento del modelo de personalización. En este ejercicio en particular no tendremos un tipo de evento ni un tipo de valor. \n",
    "\n",
    "## Elija un conjunto de datos o un origen de datos <a class=\"anchor\" id=\"source\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Como ya lo mencionamos, los datos de la interacción del usuario con los elementos son cruciales para comenzar con el servicio. Esto significa que necesitamos buscar los casos de uso que generan ese tipo de datos, algunos ejemplos comunes son los siguientes:\n",
    "\n",
    "1. Aplicaciones de video bajo demanda\n",
    "1. Plataformas de comercio electrónico\n",
    "1. Agregadores/plataformas de redes sociales\n",
    "\n",
    "Existen algunas pautas para evaluar un problema que sea adecuado para Personalize. Como punto inicial, recomendamos los valores que figuran a continuación, aunque los [límites oficiales](https://docs.aws.amazon.com/personalize/latest/dg/limits.html) son un poco más bajos.\n",
    "\n",
    "* Usuarios autenticados\n",
    "* Al menos 50 usuarios exclusivos\n",
    "* Al menos 100 elementos exclusivos\n",
    "* Al menos 2 docenas de interacciones para cada usuario \n",
    "\n",
    "La mayoría de las veces esto es fácil de lograr, y si no llega a esta cantidad en alguna categoría, puede compensarlo con una mayor cantidad en otra categoría.\n",
    "\n",
    "En general, Personalize no enviará los datos en forma perfecta y deberá realizar algunas modificaciones para que la estructura sea la correcta. Este cuaderno tiene como fin guiarlo en este proceso. \n",
    "\n",
    "Para comenzar, utilizaremos el conjunto de datos de [Last.FM](https://grouplens.org/datasets/hetrec-2011/). Estos son registros del comportamiento de escucha musical de los usuarios. Los datos son adecuados para nuestras pautas con una gran cantidad de usuarios, elementos e interacciones.\n",
    "\n",
    "Primero, descargará el conjunto de datos y lo extraerá en una nueva carpeta por medio del código que aparece a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "!mkdir $data_dir\n",
    "!cd $data_dir && wget http://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip\n",
    "!cd $data_dir && unzip hetrec2011-lastfm-2k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe los archivos de datos que ha descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente, no se sabe mucho acerca de los datos, excepto que parece que hay muchos archivos .dat y un archivo README. Si abrimos el archivo README, este nos dará información acerca de la estructura general de estos datos. Este es un paso que quizá pueda omitir con datos personalizados, a menos que el origen de datos provenga de un equipo externo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del archivo README, podemos ver que existen varios tipos de interacciones en este conjunto de datos. Las interacciones entre usuarios que se definen como amigos entre ellos, las interacciones de usuarios que escuchan a artistas y las interacciones de etiquetas asignadas a los usuarios y artistas.\n",
    "\n",
    "En este caso, nos enfocamos en los usuarios, los artistas y las interacciones de escucha. Tenemos 1892 usuarios, 17 632 artistas (nuestros elementos en este caso) y 92 834 interacciones de escucha de artistas por parte de usuarios. Esto es más que suficiente para que comencemos con Personalize.\n",
    "\n",
    "Continúe leyendo atentamente el archivo README para llegar a la sección `Files`. La mayoría de los archivos en el conjunto de datos no son relevantes para nosotros, pero el archivo `users_artists.dat` se ve prometedor. La sección `Data format` del archivo README, proporciona más detalles sobre el contenido del archivo. Aquí es donde nos encontramos con el primer problema.\n",
    "\n",
    "| userID | artistID | ponderación  |\n",
    "|--------|----------|---------|\n",
    "| 2      | 51       | 13883   |\n",
    "\n",
    "Aunque existen datos de interacción entre los usuarios y los artistas que escuchan, estas interacciones quedan guardadas como ponderaciones, en lugar de marcas temporales. Para Amazon Personalize, necesitamos los datos de marcas temporales de la interacción entre el usuario y los elementos. \n",
    "\n",
    "Si observa nuevamente los archivos en el conjunto de datos, debería poder ver que `users_taggedartists-timestamps.dat` contiene datos de marca temporal. Entonces, ¿qué sucede si en lugar del comportamiento de escucha, utilizamos el comportamiento de etiquetado como nuestros datos de interacción? ¿Podemos suponer que si un usuario etiqueta a un artista esto indica un sentimiento positivo? Normalmente, lo discutiría con el cliente o alguien que tenga conocimiento de dominio para comprender si esta interacción es adecuada para el caso de uso que desea resolver. Por ahora, supondremos que el comportamiento de etiquetado es adecuado para nuestras necesidades. \n",
    "\n",
    "El esquema para `user_taggedartists-timestamps.dat` es:\n",
    "\n",
    "| userID | artistID | tagID | timestamp (marca temporal)     |\n",
    "|--------|----------|-------|---------------|\n",
    "| 2      | 52       | 13    | 1238536800000 |\n",
    "\n",
    "Si eliminamos el atributo `tagID`, tenemos exactamente el formato que necesitamos para Amazon Personalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare los datos <a class=\"anchor\" id=\"prepare\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Lo que debe hacer a continuación es cargar los datos y confirmar que los datos se encuentran en buen estado. Luego, debe guardarlos en un archivo CSV donde estén listos para su uso con Amazon Personalize.\n",
    "\n",
    "Para comenzar, importe una recopilación de bibliotecas de Python que se utilicen normalmente en la ciencia de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, abra el archivo de datos y observe varias de las primeras filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(data_dir + '/user_taggedartists-timestamps.dat')\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, los datos no se cargaron de forma correcta. El delimitador predeterminado para los archivos CSV (valores separados por comas) es una coma (`,`), pero en este caso el archivo se guardó con delimitadores de pestaña (`\\t`). Entonces, especifiquemos el delimitador correcto e intentemos cargar los datos nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(data_dir + '/user_taggedartists-timestamps.dat', delimiter='\\t')\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso es mejor. Ahora que se han cargado los datos correctamente en la memoria, extraigamos información adicional. Primero, calculemos algunas estadísticas básicas a partir de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto muestra que tenemos un buen rango de valores para `userID` y `artistID`. Luego, siempre es una buena idea confirmar el formato de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a esto, puede ver que hay un total de 186 479 entradas en el conjunto de datos, con 4 columnas y cada celda almacenada en formato int64.\n",
    "\n",
    "El formato int64 es claramente adecuado para `userID` y `artistID`. Sin embargo, necesitamos examinar más a fondo para comprender las marcas temporales en los datos. Para utilizar Amazon Personalize, necesita guardar las marcas temporales en el formato [Unix Epoch (época de Unix)](https://en.wikipedia.org/wiki/Unix_time).\n",
    "\n",
    "Actualmente, los valores de las marcas temporales no son legibles para el ser humano. Así que tomemos un valor de marca temporal arbitrario y resolvamos cómo interpretarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_time_stamp = original_data.iloc[50]['timestamp']\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ups! Para este valor de marca temporal en particular, el código generó el año 41 132. Eso es un futuro algo lejano para nosotros, por lo que claramente esta no era la forma correcta de analizar los datos. Necesitamos hacer un segundo intento.\n",
    "\n",
    "JavaScript registra el tiempo en milisegundos y esta es una recopilación de datos de una aplicación web, así que dividamos el valor de la marca temporal por 1000 antes de aplicar nuestro código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_time_stamp = arb_time_stamp/1000\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Febrero de 2009 se siente mucho más realista para nuestro conjunto de datos. Aunque no necesitamos marcas temporales legibles para humanos para utilizar Amazon Personalize, sí queremos que las fechas sean realistas, así que ahora transforme cada marca temporal en un conjunto de datos alejado del formato de milisegundos de JavaScript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.timestamp = original_data.timestamp / 1000\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga una comprobación de validez rápida en el conjunto de datos transformado mediante la elección de una marca temporal arbitraria y su transformación a un formato legible para humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_time_stamp = original_data.iloc[50]['timestamp']\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos son coherentes como una marca temporal, para que podamos continuar formateando el resto de los datos. Recuerde que los datos que necesitamos son datos de interacción entre el usuario y los elementos, que serían `userID`, `artistID` y `timestamp` en este caso. Nuestro conjunto de datos tiene una columna adicional, `tagID`, la cual se puede eliminar del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = original_data.copy()\n",
    "interactions_df = interactions_df[['userID', 'artistID', 'timestamp']]\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de manipular los datos, siempre confirme si el formato de datos ha sido modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la columna de marca temporal pasó de int64 a float64. Entonces cambiemos el formato de vuelta a int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.astype({'timestamp': 'int64'}).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Amazon Personalize tiene nombres de columnas predeterminados para los usuarios, los elementos y las marcas temporales. Estos nombres de columnas predeterminados son `USER_ID`, `ITEM_ID` Y `TIMESTAMP`. Por lo que la última modificación del conjunto de datos es reemplazar la columna de encabezados existente por los encabezados predeterminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.rename(columns = {'userID':'USER_ID', 'artistID':'ITEM_ID', \n",
    "                              'timestamp':'TIMESTAMP'}, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Eso es todo! A esta altura, los datos están listos y solo necesitamos guardarlos como un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_filename = \"interactions.csv\"\n",
    "interactions_df.to_csv((data_dir+\"/\"+interactions_filename), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear grupos de conjuntos de datos y el conjunto de datos de las interacciones <a class=\"anchor\" id=\"group_dataset\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "El nivel más alto de aislamiento y abstracción con Amazon Personalize es un *grupo de conjuntos de datos*. La información almacenada dentro de uno de estos grupos de conjunto de datos no afecta ninguno de los demás grupos de conjuntos de datos o modelos creados de uno de ellos; están completamente aislados. Esto permite ejecutar muchos experimentos y es parte de lo que hacemos para mantener a los modelos de forma privada y completamente entrenados en sus datos. \n",
    "\n",
    "Antes de importar los datos que preparó antes, debe haber un grupo de conjuntos de datos y un conjunto de datos agregados a este que maneje las interacciones.\n",
    "\n",
    "Los grupos de conjuntos de datos pueden almacenar los siguientes tipos de información:\n",
    "\n",
    "* Interacciones entre el usuario y el elemento\n",
    "* Flujo de eventos (interacciones en tiempo real)\n",
    "* Metadatos del usuario\n",
    "* Metadatos del elemento\n",
    "\n",
    "Antes de crear el grupo de conjuntos de datos y el conjunto de datos para nuestros datos de interacción, validemos que su entorno se pueda comunicar exitosamente con Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el grupo de conjuntos de datos\n",
    "\n",
    "La siguiente celda creará un nuevo grupo de conjuntos de datos con el nombre `personalize-poc-lastfm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-batch-recommendations-dg\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos utilizar el grupo de conjuntos de datos, este debe estar activo. Esto puede llevar uno o dos minutos. Ejecute la celda a continuación y aguarde hasta que muestre el estado ACTIVO. Esto verifica el estado del grupo de conjuntos de datos a cada segundo, hasta por un máximo de 3 horas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tiene un grupo de conjuntos de datos, puede crear un conjunto de datos para los datos de interacción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el conjunto de datos\n",
    "\n",
    "Primero, defina un esquema para indicar a Amazon Personalize el tipo de conjunto de datos que está cargando. Existen varias palabras clave reservadas y obligatorias, necesarias para el esquema, según el tipo de conjunto de datos. Para obtener más información, consulte la [documentación](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "Aquí, creará un esquema para datos de interacciones, para lo que se necesitan los campos `USER_ID`, `ITEM_ID` y `TIMESTAMP`. En el esquema, estos deben estar definidos en el mismo orden que aparecen el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema = schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-batch-recommendations-interactions\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un esquema creado, puede crear un conjunto de datos dentro del grupo de conjuntos de datos. Nota: Esto aún no carga los datos. Esto sucederá unos pasos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-batch-recommendations-ds\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar un bucket de S3 y un rol de IAM <a class=\"anchor\" id=\"bucket_role\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Hasta ahora, hemos descargado, manipulado y guardado los datos en la instancia de Amazon EBS adjunta a la instancia que ejecuta este cuaderno de Jupyter. Sin embargo, Amazon Personalize necesitará un bucket de S3 para actuar como origen de los datos, así como roles de IAM para acceder a ese bucket. Preparemos todo esto.\n",
    "\n",
    "Utilice los metadatos almacenados en la instancia subyacente a este cuaderno de Amazon SageMaker para determinar la región en la que opera. Si utiliza un cuaderno de Jupyter fuera de Amazon SageMaker, simplemente defina la región como una cadena a continuación. El bucket de Amazon S3 debe estar en la misma región que los recursos de Amazon Personalize que hemos creado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de los buckets de Amazon S3 son exclusivos a nivel global. Para crear un nombre de bucket exclusivo, el siguiente código agregará la cadena `personalizepoc` a su número de cuenta de AWS. Luego, crea un bucket con este nombre en la región descubierta en la celda anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"-personalize-batch-recommendations\"\n",
    "print(bucket_name)\n",
    "if region != \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "else:\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos a S3\n",
    "\n",
    "Ahora que creó su bucket de Amazon S3, cargue el archivo CSV de nuestros datos de interacción entre el usuario y los elementos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_file_path = data_dir + \"/\" + interactions_filename\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(interactions_filename).upload_file(interactions_file_path)\n",
    "interactions_s3DataPath = \"s3://\"+bucket_name+\"/\"+interactions_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecer la política del bucket de S3\n",
    "Amazon Personalize debe ser capaz de leer el contenido de su bucket de S3. Así que agregue una política de bucket que lo permita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un rol de IAM\n",
    "\n",
    "Amazon Personalize necesita la capacidad de asumir roles en AWS de modo que tenga los permisos para ejecutar ciertas tareas. Creemos un rol de IAM y adjuntemos las políticas necesarias a este. El siguiente código adjunta políticas muy permisivas. Utilice políticas más restrictivas para cualquier aplicación en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRoleBatchRecommendations\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los datos de las interacciones <a class=\"anchor\" id=\"import\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Anteriormente, creó el grupo de conjuntos de datos y el conjunto de datos para alojar su información. Ahora ejecutará un trabajo de importación que cargará los datos del bucket de S3 en el conjunto de datos de Amazon Personalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-batch-recommendations\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos utilizar el grupo de conjuntos de datos, el trabajo de importación debe estar activo. Ejecute la celda a continuación y aguarde hasta que muestre el estado ACTIVO. Esto verifica el estado del trabajo de importación a cada segundo, por hasta un máximo de 3 horas.\n",
    "\n",
    "La importación de los datos puede llevar algo de tiempo, según el tamaño del conjunto de datos. En este taller, el trabajo de importación debería tomar alrededor de 15 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando la importación del conjunto de datos está activa, está listo para comenzar a crear modelos con SIMS, clasificaciones personalizadas, recuentos de popularidad y personalización de usuario de AWS. Este proceso continuará en otros cuadernos. Ejecute la celda a continuación antes de pasar a almacenar algunos valores para su uso en los siguientes cuadernos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear soluciones <a class=\"anchor\" id=\"solutions\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "En este cuaderno, creará soluciones con las siguientes recetas:\n",
    "\n",
    "1. Personalización del usuario de AWS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una variación específica de un algoritmo se denomina receta en Amazon Personalize. Las diferentes recetas son adecuadas para diferentes situaciones. Un modelo entrenado se denomina solución, y cada solución puede tener muchas versiones relacionadas con un determinado volumen de datos cuando se entrenó el modelo.\n",
    "\n",
    "Para comenzar, enumeraremos todas las recetas que son compatibles. Esto le permitirá seleccionar una y utilizarla para crear el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es solo una representación JSON de todos los algoritmos mencionados en la introducción.\n",
    "\n",
    "A continuación, seleccionaremos recetas específicas y crearemos modelos con ellas.\n",
    "\n",
    "### Personalización del usuario de AWS\n",
    "\n",
    "La personalización de usuario de AWS es uno de los modelos de recomendación más avanzados que puede utilizar y que permite actualizaciones en tiempo real de recomendaciones basadas en el comportamiento del usuario. También tiende a conseguir mejores resultados que otros enfoques, como el filtrado colaborativo. La receta requiere el entrenamiento más largo, así que comencemos con esta receta primero.\n",
    "\n",
    "Para nuestro caso de uso, mediante los datos de LastFM, podemos utilizar el algoritmo de personalización del usuario de AWS para recomendar nuevos artistas a un usuario en base al comportamiento previo de etiquetado de artistas de un usuario. Recuerde que hemos utilizado datos de etiquetas para representar interacciones positivas entre un usuario y un artista.\n",
    "\n",
    "En primer lugar, seleccione la receta buscando el ARN en la lista de recetas anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear la solución\n",
    "\n",
    "Primero cree una solución con la receta. Aunque en este paso se proporciona el conjunto de datos ARN, el modelo aún no está entrenado. Véalo como un identificador en lugar de un modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-batch-recommendations-user-personalization\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear la versión de la solución\n",
    "\n",
    "Una vez que tenga una solución, deberá crear una versión a fin de completar el entrenamiento del modelo. Completar el entrenamiento puede llevar un tiempo, más de 25 minutos, y un promedio de 40 minutos para esta receta con nuestro conjunto de datos. Por lo general, utilizaríamos un bucle while para hacer un seguimiento hasta que se complete la tarea. Sin embargo, la tarea bloquearía la ejecución de otras celdas, y el objetivo aquí es crear muchos modelos e implementarlos rápidamente. Así que estableceremos el bucle while para todas las soluciones más adelante en el cuaderno. Allí, también encontrará instrucciones para ver el progreso en la consola de AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver el estado de creación de la solución\n",
    "\n",
    "Según lo prometido, veremos cómo se pueden observar las actualizaciones de estado en la consola:\n",
    "\n",
    "* En otra pestaña del navegador, ya debería tener la consola de AWS activa desde la apertura de esta instancia de cuaderno. \n",
    "* Cambie a esa pestaña y busque en la parte superior el servicio `Personalize`, luego diríjase a la página de ese servicio. \n",
    "* Haga clic en `View dataset groups` (Ver grupos de conjuntos de datos).\n",
    "* Haga clic en el nombre de su grupo de conjuntos de datos, probablemente contenga POC en el nombre.\n",
    "* Haga clic en `Solutions and recipes` (Ver grupos de conjuntos de datos).\n",
    "* Ahora verá una lista de todas las soluciones que creó anteriormente, incluida una columna con el estado de las versiones de la solución. Una vez que esté `Active` (ACTIVA), su solución estará lista para la revisión. También es capaz de implementarse.\n",
    "\n",
    "O simplemente ejecute la celda a continuación para seguir el estado de creación de la versión de la solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_progress_solution_versions = [\n",
    "    solution_version_arn,\n",
    "]\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    for solution_version_arn in in_progress_solution_versions:\n",
    "        version_response = personalize.describe_solution_version(\n",
    "            solutionVersionArn = solution_version_arn\n",
    "        )\n",
    "        status = version_response[\"solutionVersion\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "    \n",
    "    if len(in_progress_solution_versions) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one solution build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacción con las soluciones <a class=\"anchor\" id=\"interact\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Ahora que todas las soluciones se han implementado, podemos comenzar a recibir recomendaciones a través de una llamada de API. \n",
    "\n",
    "Comience descargando el conjunto de datos que podemos utilizar para nuestra tabla de búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the items by reading in the correct source CSV\n",
    "items_df = pd.read_csv(data_dir + '/artists.dat', delimiter='\\t', index_col=0)\n",
    "\n",
    "# Render some sample data\n",
    "items_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando definimos la columna ID como una columna índice, es común que devuelva un artista con tan solo buscar el ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_example = 987\n",
    "artist = items_df.loc[item_id_example]['name']\n",
    "print(artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso no es malo, pero se podría volver complicado tener que repetir esto en cada parte de nuestro código, por lo que la siguiente función facilitará esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_by_id(artist_id, artist_df=items_df):\n",
    "    \"\"\"\n",
    "    This takes in an artist_id from Personalize so it will be a string,\n",
    "    converts it to an int, and then does a lookup in a default or specified\n",
    "    dataframe.\n",
    "    \n",
    "    A really broad try/except clause was added in case anything goes wrong.\n",
    "    \n",
    "    Feel free to add more debugging or filtering here to improve results if\n",
    "    you hit an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return artist_df.loc[int(artist_id)]['name']\n",
    "    except:\n",
    "        return \"Error obtaining artist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos con algunos valores simples para verificar nuestra detección de errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A known good id\n",
    "print(get_artist_by_id(artist_id=\"987\"))\n",
    "# A bad type of value\n",
    "print(get_artist_by_id(artist_id=\"987.9393939\"))\n",
    "# Really bad values\n",
    "print(get_artist_by_id(artist_id=\"Steve\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Genial! Ahora tenemos una forma de conseguir resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones por lote <a class=\"anchor\" id=\"batch\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Existen muchos casos en los que quizá desee tener un mayor conjunto de datos de recomendaciones exportadas. Recientemente, Amazon Personalize lanzó recomendaciones por lote como una forma de exportar una colección de recomendaciones a S3. En este ejemplo, le explicaremos cómo hacer esto para la solución de personalización del usuario de AWS. Para obtener más información sobre las recomendaciones por lote, consulte la [documentación](https://docs.aws.amazon.com/personalize/latest/dg/getting-recommendations.html#recommendations-batch). Esta característica se aplica a todas las recetas, pero el formato de salida variará.\n",
    "\n",
    "Una implementación sencilla tiene la siguiente apariencia:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "personalize_rec = boto3.client(service_name='personalize')\n",
    "\n",
    "personalize_rec.create_batch_inference_job (\n",
    "    solutionVersionArn = \"Solution version ARN\",\n",
    "    jobName = \"Batch job name\",\n",
    "    roleArn = \"IAM role ARN\",\n",
    "    jobInput = \n",
    "       {\"s3DataSource\": {\"path\": S3 input path}},\n",
    "    jobOutput = \n",
    "       {\"s3DataDestination\": {\"path\":S3 output path\"}}\n",
    ")\n",
    "```\n",
    "\n",
    "Se ha determinado la importación SDK, la versión de la solución de arn y los roles de arn. Esto solo deja una entrada, una salida y un nombre de trabajo por definir.\n",
    "\n",
    "Comencemos con la entrada para la Personalización del usuario que tiene la siguiente apariencia:\n",
    "\n",
    "\n",
    "```JSON\n",
    "{\"userId\": \"4638\"}\n",
    "{\"userId\": \"663\"}\n",
    "{\"userId\": \"3384\"}\n",
    "```\n",
    "\n",
    "Esto debería generar una salida con la siguiente apariencia:\n",
    "\n",
    "```JSON\n",
    "{\"input\":{\"userId\":\"4638\"}, \"output\": {\"recommendedItems\": [\"296\", \"1\", \"260\", \"318\"]}}\n",
    "{\"input\":{\"userId\":\"663\"}, \"output\": {\"recommendedItems\": [\"1393\", \"3793\", \"2701\", \"3826\"]}}\n",
    "{\"input\":{\"userId\":\"3384\"}, \"output\": {\"recommendedItems\": [\"8368\", \"5989\", \"40815\", \"48780\"]}}\n",
    "```\n",
    "\n",
    "La salida es un archivo JSON Lines. Consiste en objetos JSON individuales, uno por línea. Así que luego necesitaremos trabajar más para asimilar los resultados en este formato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del archivo de entrada\n",
    "\n",
    "Cuando utiliza la característica de lote, usted especifica los usuarios que desea que reciban recomendaciones para el momento en el que se haya completado el trabajo. La celda que aparece a continuación seleccionará nuevamente y de forma aleatoria a algunos usuarios y, luego, creará el archivo y lo guardará en el disco. A partir de allí, lo cargará al S3 para utilizarlo luego en la llamada a la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(data_dir + '/user_artists.dat', delimiter='\\t', index_col=0)\n",
    "# Render some sample data\n",
    "users_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user list\n",
    "batch_users = users_df.sample(3).index.tolist()\n",
    "\n",
    "# Write the file to disk\n",
    "json_input_filename = \"json_input.json\"\n",
    "with open(data_dir + \"/\" + json_input_filename, 'w') as json_input:\n",
    "    for user_id in batch_users:\n",
    "        json_input.write('{\"userId\": \"' + str(user_id) + '\"}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase the input file:\n",
    "!cat $data_dir\"/\"$json_input_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue el archivo a S3 y guarde el trayecto como una variable para más tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to S3\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(json_input_filename).upload_file(data_dir+\"/\"+json_input_filename)\n",
    "s3_input_path = \"s3://\" + bucket_name + \"/\" + json_input_filename\n",
    "print(s3_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las recomendaciones por lote leen la entrada del archivo que hemos subido al S3. De forma similar, las recomendaciones por lote guardarán el archivo de salida en el S3. Así que definimos el trayecto de salida donde se deberían guardar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path\n",
    "s3_output_path = \"s3://\" + bucket_name + \"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo hagamos la llamada para poner en marcha el proceso de exportación del lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchInferenceJobArn = personalize.create_batch_inference_job (\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    jobName = \"Batch-Inference-Job\",\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
    ")\n",
    "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el bucle while a continuación para hacer un seguimiento del estado de la llamada de recomendación por lote. Esto puede llevar alrededor de 25 minutos en completarse debido a que Personalize necesita soportar la infraestructura para llevar a cabo la tarea. Estamos probando la característica con un conjunto de datos de solo 3 usuarios, lo que no es un uso eficiente de este mecanismo. Normalmente, solo utilizaría esta característica para el procesamiento en masa, caso en el que las eficiencias se volverán claras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se han terminado de procesar las recomendaciones por lote, podemos tomar el resultado cargado a S3 y analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "export_name = json_input_filename + \".out\"\n",
    "s3.download_file(bucket_name, export_name, data_dir+\"/\"+export_name)\n",
    "\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "with open(data_dir+\"/\"+export_name) as json_file:\n",
    "    # Get the first line and parse it\n",
    "    line = json.loads(json_file.readline())\n",
    "    # Do the same for the other lines\n",
    "    while line:\n",
    "        # extract the user ID \n",
    "        col_header = \"User: \" + line['input']['userId']\n",
    "        # Create a list for all the artists\n",
    "        recommendation_list = []\n",
    "        # Add all the entries\n",
    "        for item in line['output']['recommendedItems']:\n",
    "            artist = get_artist_by_id(item)\n",
    "            recommendation_list.append(artist)\n",
    "        if 'bulk_recommendations_df' in locals():\n",
    "            new_rec_DF = pd.DataFrame(recommendation_list, columns = [col_header])\n",
    "            bulk_recommendations_df = bulk_recommendations_df.join(new_rec_DF)\n",
    "        else:\n",
    "            bulk_recommendations_df = pd.DataFrame(recommendation_list, columns=[col_header])\n",
    "        try:\n",
    "            line = json.loads(json_file.readline())\n",
    "        except:\n",
    "            line = None\n",
    "bulk_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar soluciones\n",
    "\n",
    "Luego, limpie las soluciones. El código que aparece a continuación enumerará todas las soluciones en la cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = personalize.get_paginator('list_solutions')\n",
    "for paginate_result in paginator.paginate():\n",
    "    for solution in paginate_result[\"solutions\"]:\n",
    "        print(solution[\"solutionArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise la lista de los ARN para determinar cuál solución desea eliminar. Luego, utilice el código que aparece a continuación para eliminarlo insertando el ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.delete_solution(\n",
    "    solutionArn = \"INSERT ARN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar conjuntos de datos\n",
    "\n",
    "Luego, limpie los conjuntos de datos. El código que aparece a continuación enumerará todos los conjuntos de datos en la cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = personalize.get_paginator('list_datasets')\n",
    "for paginate_result in paginator.paginate():\n",
    "    for datasets in paginate_result[\"datasets\"]:\n",
    "        print(datasets[\"datasetArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise la lista de los ARN para determinar qué conjunto de datos desea eliminar. Luego, utilice el código que aparece a continuación para eliminarlo insertando el ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.delete_dataset(\n",
    "    datasetArn = \"INSERT ARN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar esquemas\n",
    "\n",
    "Luego, limpie los esquemas. El código que aparece a continuación enumerará todos los esquemas en la cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = personalize.get_paginator('list_schemas')\n",
    "for paginate_result in paginator.paginate():\n",
    "    for schema in paginate_result[\"schemas\"]:\n",
    "        print(schema[\"schemaArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise la lista de los ARN para determinar qué esquema desea eliminar. Luego, utilice el código que aparece a continuación para eliminarlo insertando el ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.delete_schema(\n",
    "    schemaArn = \"INSERT ARN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar grupos de conjuntos de datos\n",
    "\n",
    "Por último, limpie el grupo de conjuntos de datos. El código que aparece a continuación enumerará todos los grupos de conjuntos de datos en la cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = personalize.get_paginator('list_dataset_groups')\n",
    "for paginate_result in paginator.paginate():\n",
    "    for dataset_group in paginate_result[\"datasetGroups\"]:\n",
    "        print(dataset_group[\"datasetGroupArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revise la lista de los ARN para determinar qué grupo de conjuntos de datos desea eliminar. Luego, utilice el código que aparece a continuación para eliminarlo insertando el ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize.delete_dataset_group(\n",
    "    datasetGroupArn = \"INSERT ARN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar bucket de S3 y rol de IAM\n",
    "\n",
    "De forma opcional, puede eliminar el rol de IAM y el bucket de S3 que creamos a lo largo del curso.\n",
    "\n",
    "Comience por enumerar todos los roles de IAM en la cuenta con el código que aparece a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')\n",
    "\n",
    "paginator = iam.get_paginator('list_roles')\n",
    "for paginate_result in paginator.paginate():\n",
    "    for roles in paginate_result[\"Roles\"]:\n",
    "        print(roles[\"RoleName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifique el nombre del rol que desea eliminar.\n",
    "\n",
    "No puede eliminar un rol de IAM que aún tiene políticas adjuntas. Después de que identifique el rol relevante, enumere las políticas adjuntas a ese rol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.list_attached_role_policies(\n",
    "    RoleName = \"INSERT ROLE NAME HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debe desconectar las políticas en el resultado anterior mediante el código que aparece a continuación. Repita este paso para cada política adjunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(\n",
    "    RoleName = \"INSERT ROLE NAME HERE\",\n",
    "    PolicyArn = \"INSERT ARN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, debería poder eliminar el rol de IAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.delete_role(\n",
    "    RoleName = \"INSERT ROLE NAME HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar un bucket de S3, primero debe estar vacío. La forma más sencilla de eliminar un bucket de S3 es simplemente navegar a S3 en la consola de AWS, eliminar los objetos en el bucket y, luego, eliminar el bucket de S3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
