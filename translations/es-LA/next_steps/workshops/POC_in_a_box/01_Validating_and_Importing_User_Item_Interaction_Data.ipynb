{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación e importación de los datos de interacción entre el usuario y los elementos<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "En este cuaderno, elegirá un conjunto de datos y lo preparará para utilizarlo con Amazon Personalize.\n",
    "\n",
    "1. [Introducción](#intro)\n",
    "1. [Elija un conjunto de datos o un origen de datos](#source)\n",
    "1. [Prepare los datos](#prepare)\n",
    "1. [Crear grupos de conjuntos de datos y el conjunto de datos de las interacciones](#group_dataset)\n",
    "1. [Configurar un bucket de S3 y un rol de IAM](#bucket_role)\n",
    "1. [Importar los datos de las interacciones](#import)\n",
    "\n",
    "## Introducción <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Por lo general, los algoritmos en Amazon Personalize (llamados recetas) buscan resolver diferentes tareas que se explican a continuación:\n",
    "\n",
    "1. **User Personalization (Personalización del usuario)**: nueva versión que admite TODOS los flujos de trabajo de HRNN/necesidades de personalización del usuario, será lo que utilicemos aquí.\n",
    "1. **HRNN & HRNN-Metadata**: recomienda elementos basados en las interacciones previas del usuario con los elementos.\n",
    "1. **HRNN-Coldstart**: recomienda nuevos elementos para los que aún no se dispone de datos de interacción.\n",
    "1. **Personalized-Ranking**: toma una recopilación de elementos y, luego, los ubica en un posible orden de interés mediante un enfoque similar al de una HRNN.\n",
    "1. **SIMS (elementos similares)**: en base a un elemento, recomienda otros elementos con los que también interactúan los usuarios.\n",
    "1. **Popularity-Count**: recomienda los elementos más populares, si la HRNN o los metadatos de la HRNN no ofrecen una respuesta. Esta es la devolución predeterminada.\n",
    "\n",
    "Sin importar cuál sea el caso de uso, todos los algoritmos comparten una base de aprendizaje sobre los datos de interacción entre el usuario y los elementos, la cual se define según 3 atributos principales:\n",
    "\n",
    "1. **UserID**: el usuario que interactuó\n",
    "1. **ItemID**: el elemento con el que interactuó el usuario\n",
    "1. **Timestamp (Marca temporal)**: la hora a la que ocurrió la interacción\n",
    "\n",
    "También admitimos los tipos de eventos y valores de eventos definidos por lo siguiente:\n",
    "\n",
    "1. **Tipo de evento**: etiquetado de eventos por categoría (navegación, compra, clasificación, etc.).\n",
    "1. **Valor de evento**: valor que corresponde al tipo de evento acontecido. En términos generales, buscamos valores normalizados entre 0 y 1 entre los tipos de eventos. Por ejemplo, si existen tres fases para completar una transacción (seleccionar, agregar al carrito y comprar), entonces hay un valor de evento para cada fase, como 0.33, 0.66 y 1.0, respectivamente.\n",
    "\n",
    "Los campos para el tipo de evento y valor de evento son datos adicionales que se pueden utilizar para filtrar los datos enviados para el entrenamiento del modelo de personalización. En este ejercicio en particular no tendremos un tipo de evento ni un tipo de valor. \n",
    "\n",
    "## Elija un conjunto de datos o un origen de datos <a class=\"anchor\" id=\"source\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Como ya lo mencionamos, los datos de la interacción del usuario con los elementos son cruciales para comenzar con el servicio. Esto significa que necesitamos buscar los casos de uso que generan ese tipo de datos, algunos ejemplos comunes son los siguientes:\n",
    "\n",
    "1. Aplicaciones de video bajo demanda\n",
    "1. Plataformas de comercio electrónico\n",
    "1. Agregadores/plataformas de redes sociales\n",
    "\n",
    "Existen algunas pautas para evaluar un problema que sea adecuado para Personalize. Como punto inicial, recomendamos los valores que figuran a continuación, aunque los [límites oficiales](https://docs.aws.amazon.com/personalize/latest/dg/limits.html) son un poco más bajos.\n",
    "\n",
    "* Usuarios autenticados\n",
    "* Al menos 50 usuarios exclusivos\n",
    "* Al menos 100 elementos exclusivos\n",
    "* Al menos 2 docenas de interacciones para cada usuario \n",
    "\n",
    "La mayoría de las veces esto es fácil de lograr, y si no llega a esta cantidad en alguna categoría, puede compensarlo con una mayor cantidad en otra categoría.\n",
    "\n",
    "En general, Personalize no enviará los datos en forma perfecta y deberá realizar algunas modificaciones para que la estructura sea la correcta. Este cuaderno tiene como fin guiarlo en este proceso. \n",
    "\n",
    "Para comenzar, utilizaremos el último conjunto de datos de MovieLens, que cuenta con más de 25 millones de interacciones y una rica recopilación de metadatos para los elementos. También hay una versión más pequeña de este conjunto de datos, que se puede utilizar para acortar los tiempos de entrenamiento, sin dejar de incorporar las mismas capacidades que el conjunto de datos completo. Establezca USE_FULL_MOVIELENS en True (Verdadero) para utilizar el conjuntos de datos completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FULL_MOVIELENS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, descargará el conjunto de datos y lo extraerá en una nueva carpeta por medio del código que aparece a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"poc_data\"\n",
    "!mkdir $data_dir\n",
    "\n",
    "if not USE_FULL_MOVIELENS:\n",
    "    !cd $data_dir && wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "    !cd $data_dir && unzip ml-latest-small.zip\n",
    "    dataset_dir = data_dir + \"/ml-latest-small/\"\n",
    "else:\n",
    "    !cd $data_dir && wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
    "    !cd $data_dir && unzip ml-25m.zip\n",
    "    dataset_dir = data_dir + \"/ml-25m/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe los archivos de datos que ha descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este momento no hay mucha información, salvo que tenemos unos cuantos archivos CSV y un archivo README. A continuación, generaremos el archivo README para obtener más información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize $dataset_dir/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el archivo README, vemos que hay un archivo `ratings.csv` que debería funcionar como un proxy para nuestros datos de las interacciones. En definitiva, calificar una película sin dudas es una forma de interactuar con ella. El conjunto de datos también tiene algo de información sobre el género, como algunos datos del genoma de la película. En esta POC, nos centraremos en las interacciones y los datos sobre el género.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare los datos <a class=\"anchor\" id=\"prepare\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Lo que debe hacer a continuación es cargar los datos y confirmar que los datos se encuentran en buen estado. Luego, debe guardarlos en un archivo CSV donde estén listos para su uso con Amazon Personalize.\n",
    "\n",
    "Para comenzar, importe una recopilación de bibliotecas de Python que se utilicen normalmente en la ciencia de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, abra el archivo de datos y observe varias de las primeras filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(dataset_dir + '/ratings.csv')\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto muestra que tenemos un buen rango de valores para `userId` y `movieId`. Luego, siempre es una buena idea confirmar el formato de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esto, se puede ver que hay un total de 25 000 095 entradas en el conjunto de datos completo y 100 836 entradas en el pequeño, con 4 columnas, y que cada celda almacenada tiene formato int64, con la excepción de la calificación cuyo formato es float64.\n",
    "\n",
    "El formato int64 es claramente adecuado para `userId` y `movieId`. Sin embargo, necesitamos examinar más a fondo para comprender las marcas temporales en los datos. Para utilizar Amazon Personalize, necesita guardar las marcas temporales en el formato [Unix Epoch (época de Unix)](https://en.wikipedia.org/wiki/Unix_time).\n",
    "\n",
    "Actualmente, los valores de las marcas temporales no son legibles para el ser humano. Así que tomemos un valor de marca temporal arbitrario y resolvamos cómo interpretarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga una comprobación de validez rápida en el conjunto de datos transformado mediante la elección de una marca temporal arbitraria y su transformación a un formato legible para humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_time_stamp = original_data.iloc[50]['timestamp']\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos son coherentes como una marca temporal, para que podamos continuar formateando el resto de los datos. Recuerde que los datos que necesitamos son datos de interacción entre el usuario y los elementos, que serían `userId`, `movieId` y `timestamp` en este caso. Nuestro conjunto de datos tiene una columna adicional, `rating`, que puede eliminarse del conjunto de datos después de que la hayamos aprovechado para centrarnos en las interacciones positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se trata de un conjunto de datos de calificación de películas con opiniones explícitas, que incluye películas con calificaciones del 1 al 5, queremos incluir solo las movimientos que \"gustaron\" a los usuarios, y simular un conjunto de datos implícito que se asemeje más a los datos que recopilaría una plataforma VOD. Para ello filtraremos todas las interacciones entre 2 y 5, y crearemos un EVENT_Type de \"clics\" y un EVENT_Type de \"vistas\". A continuación, asignaremos todas las películas calificadas con 2 o más como \"clics\" y las películas con una clasificación mayor de 4 \"clics\" y \"vistas\".\n",
    "\n",
    "Tenga en cuenta que esto es para corresponder con los eventos que estamos modelando, para un conjunto de datos reales que en verdad modelaría en función de las opiniones implícitas, como los clics y las vistas, o de las opiniones explícitas, como las calificaciones, los “Me gusta”, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_df = original_data.copy()\n",
    "watched_df = watched_df[watched_df['rating'] > 3]\n",
    "watched_df = watched_df[['userId', 'movieId', 'timestamp']]\n",
    "watched_df['EVENT_TYPE']='watch'\n",
    "watched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df = original_data.copy()\n",
    "clicked_df = clicked_df[clicked_df['rating'] > 1]\n",
    "clicked_df = clicked_df[['userId', 'movieId', 'timestamp']]\n",
    "clicked_df['EVENT_TYPE']='click'\n",
    "clicked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = clicked_df.copy()\n",
    "interactions_df = interactions_df.append(watched_df)\n",
    "interactions_df.sort_values(\"timestamp\", axis = 0, ascending = True, \n",
    "                 inplace = True, na_position ='last') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el aspecto del conjunto de datos nuevo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de manipular los datos, siempre confirme si el formato de datos ha sido modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Amazon Personalize tiene nombres de columnas predeterminados para los usuarios, los elementos y las marcas temporales. Estos nombres de columnas predeterminados son `USER_ID`, `ITEM_ID` Y `TIMESTAMP`. Por lo que la última modificación del conjunto de datos es reemplazar la columna de encabezados existente por los encabezados predeterminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.rename(columns = {'userId':'USER_ID', 'movieId':'ITEM_ID', \n",
    "                              'timestamp':'TIMESTAMP'}, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Eso es todo! A esta altura, los datos están listos y solo necesitamos guardarlos como un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_filename = \"interactions.csv\"\n",
    "interactions_df.to_csv((data_dir+\"/\"+interactions_filename), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear grupos de conjuntos de datos y el conjunto de datos de las interacciones <a class=\"anchor\" id=\"group_dataset\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "El nivel más alto de aislamiento y abstracción con Amazon Personalize es un *grupo de conjuntos de datos*. La información almacenada dentro de uno de estos grupos de conjunto de datos no afecta ninguno de los demás grupos de conjuntos de datos o modelos creados de uno de ellos; están completamente aislados. Esto permite ejecutar muchos experimentos y es parte de lo que hacemos para mantener a los modelos de forma privada y completamente entrenados en sus datos. \n",
    "\n",
    "Antes de importar los datos que preparó antes, debe haber un grupo de conjuntos de datos y un conjunto de datos agregados a este que maneje las interacciones.\n",
    "\n",
    "Los grupos de conjuntos de datos pueden almacenar los siguientes tipos de información:\n",
    "\n",
    "* Interacciones entre el usuario y el elemento\n",
    "* Flujo de eventos (interacciones en tiempo real)\n",
    "* Metadatos del usuario\n",
    "* Metadatos del elemento\n",
    "\n",
    "Antes de crear el grupo de conjuntos de datos y el conjunto de datos para nuestros datos de interacción, validemos que su entorno se pueda comunicar exitosamente con Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el grupo de conjuntos de datos\n",
    "\n",
    "La siguiente celda creará un nuevo grupo de conjuntos de datos con el nombre `personalize-poc-lastfm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-poc-movielens\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos utilizar el grupo de conjuntos de datos, este debe estar activo. Esto puede llevar uno o dos minutos. Ejecute la celda a continuación y aguarde hasta que muestre el estado ACTIVO. Esto verifica el estado del grupo de conjuntos de datos a cada segundo, hasta por un máximo de 3 horas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tiene un grupo de conjuntos de datos, puede crear un conjunto de datos para los datos de interacción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el conjunto de datos\n",
    "\n",
    "Primero, defina un esquema para indicar a Amazon Personalize el tipo de conjunto de datos que está cargando. Existen varias palabras clave reservadas y obligatorias, necesarias para el esquema, según el tipo de conjunto de datos. Para obtener más información, consulte la [documentación](https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html).\n",
    "\n",
    "Aquí, creará un esquema para datos de interacciones, para lo que se necesitan los campos `USER_ID`, `ITEM_ID` y `TIMESTAMP`. En el esquema, estos deben estar definidos en el mismo orden que aparecen el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema = schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-poc-movielens-interactions\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interaction_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un esquema creado, puede crear un conjunto de datos dentro del grupo de conjuntos de datos. Nota: Esto aún no carga los datos. Esto sucederá unos pasos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-poc-movielens-ints\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interaction_schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar un bucket de S3 y un rol de IAM <a class=\"anchor\" id=\"bucket_role\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Hasta ahora, hemos descargado, manipulado y guardado los datos en la instancia de Amazon EBS adjunta a la instancia que ejecuta este cuaderno de Jupyter. Sin embargo, Amazon Personalize necesitará un bucket de S3 para actuar como origen de los datos, así como roles de IAM para acceder a ese bucket. Preparemos todo esto.\n",
    "\n",
    "Utilice los metadatos almacenados en la instancia subyacente a este cuaderno de Amazon SageMaker para determinar la región en la que opera. Si utiliza un cuaderno de Jupyter fuera de Amazon SageMaker, simplemente defina la región como una cadena a continuación. El bucket de Amazon S3 debe estar en la misma región que los recursos de Amazon Personalize que hemos creado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de los buckets de Amazon S3 son exclusivos a nivel global. Para crear un nombre de bucket exclusivo, el siguiente código agregará la cadena `personalizepocvod` a su número de cuenta de AWS. Luego, crea un bucket con este nombre en la región descubierta en la celda anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"-\" + region + \"-\" + \"personalizepocvod\"\n",
    "print(bucket_name)\n",
    "if region == \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "else:\n",
    "    s3.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos a S3\n",
    "\n",
    "Ahora que creó su bucket de Amazon S3, cargue el archivo CSV de nuestros datos de interacción entre el usuario y los elementos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_file_path = data_dir + \"/\" + interactions_filename\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(interactions_filename).upload_file(interactions_file_path)\n",
    "interactions_s3DataPath = \"s3://\"+bucket_name+\"/\"+interactions_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecer la política del bucket de S3\n",
    "Amazon Personalize debe ser capaz de leer el contenido de su bucket de S3. Así que agregue una política de bucket que lo permita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un rol de IAM\n",
    "\n",
    "Amazon Personalize necesita la capacidad de asumir roles en AWS de modo que tenga los permisos para ejecutar ciertas tareas. Creemos un rol de IAM y adjuntemos las políticas necesarias a este. El siguiente código adjunta políticas muy permisivas. Utilice políticas más restrictivas para cualquier aplicación en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRolePOC\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los datos de interacción <a class=\"anchor\" id=\"import\"></a>\n",
    "[Regresar al principio](#top)\n",
    "\n",
    "Anteriormente, creó el grupo de conjuntos de datos y el conjunto de datos para alojar su información. Ahora ejecutará un trabajo de importación que cargará los datos del bucket de S3 en el conjunto de datos de Amazon Personalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-poc-import1\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos utilizar el grupo de conjuntos de datos, el trabajo de importación debe estar activo. Ejecute la celda a continuación y aguarde hasta que muestre el estado ACTIVO. Esto verifica el estado del trabajo de importación a cada segundo, por hasta un máximo de 6 horas.\n",
    "\n",
    "La importación de los datos puede llevar algo de tiempo, según el tamaño del conjunto de datos. En este taller, el trabajo de importación debería tomar alrededor de 15 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando la importación del conjunto de datos está activa, está listo para comenzar a crear modelos con SIMS, Personalized-Ranking, Popularity-Count y User Personalization. Este proceso continuará en otros cuadernos. Ejecute la celda a continuación antes de pasar a almacenar algunos valores para su uso en los siguientes cuadernos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store USE_FULL_MOVIELENS\n",
    "%store dataset_dir\n",
    "%store interactions_dataset_arn\n",
    "%store dataset_group_arn\n",
    "%store bucket_name\n",
    "%store role_arn\n",
    "%store role_name\n",
    "%store data_dir\n",
    "%store region\n",
    "%store interaction_schema_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
