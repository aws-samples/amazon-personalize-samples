{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb38004e",
   "metadata": {},
   "source": [
    "# Introduction and Data Preparation\n",
    "\n",
    "## Contents\n",
    "\n",
    "This demo will walk you through how to create personalized marketing content (for instance emails) for each user using [Amazon Personalize](https://aws.amazon.com/personalize/) and [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "1. Building a work environment (follow the steps bellow)\n",
    "2. Format your data to use with [Amazon Personalize](https://aws.amazon.com/personalize/). \n",
    "3. Train an Amazon Personalize 'Top picks for you' Recommender to get personalized recommendations for each user.\n",
    "4. Generate a prompt that includes the user's preferences, recommendations, and demographics.\n",
    "5. Generate a custom email for each user with [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n",
    "\n",
    "## Architecture diagram\n",
    "\n",
    "\n",
    "<img src=\"./images/architecture.png\" alt=\"architecture_diagram\" style=\"width:800px;\"/></br>\n",
    "<center>Fig. 1 Architecture diagram.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d3157",
   "metadata": {},
   "source": [
    "## How to Use the Notebook\n",
    "\n",
    "The code is broken up into cells. There's a triangular `Run` button at the top of this page you can click to execute each cell and move onto the next, or you can press `Shift` + `Enter` while in the cell to execute it and move onto the next one.\n",
    "\n",
    "As a cell is executing you'll notice a line to the side showcase an `*` while the cell is running or it will update to a number to indicate the last cell that completed executing after it has finished exectuting all the code within a cell.\n",
    "\n",
    "Follow the instructions below and execute the cells to run this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4098651",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe80e79",
   "metadata": {},
   "source": [
    "### Items data\n",
    "\n",
    "The item data consists of information about the content that is being interacted with, this generally comes from Content Management Systems (CMS). \n",
    "\n",
    "In order provide additional metadata, and also to provide a consistent experience for our users we leverage a subset of the IMDb Essential Metadata for Movies/TV/OTT dataset. IMDb is the world's most popular and authoritative source for information on movies, TV shows, and celebrities and powers entertainment experiences around the world. License IMDb entertainment metadata from over 10 million movies, TV series, and Video Game titles including 12 million cast and crew, 1 billion star ratings, and global box office grosses from Box Office Mojo. All IMDb data products are updated daily and easily accessed through AWS Data Exchange. \n",
    "\n",
    "The IMDb Essential Metadata for Movies/TV/OTT dataset, which contains \n",
    "\n",
    "- 9+ million titles\n",
    "- 12+ million names\n",
    "- Film, TV, music and celebrities\n",
    "- 1 billion ratings from the worldâ€™s largest entertainment fan community\n",
    "\n",
    "IMDb has [multiple datasets available in the Amazon Data Exchange](https://aws.amazon.com/marketplace/seller-profile?id=0af153a3-339f-48c2-8b42-3b9fa26d3367). <img src=\"./images/IMDb_Logo_Rectangle.png\" alt=\"IMDb logo\" style=\"width:50px;\"/>\n",
    "\n",
    "For this workshop we have extracted the subset of data we needed and prepared it for use with the following information from the IMDb Essential Metadata for Movies/TV/OTT (Bulk data) dataset.\n",
    "\n",
    "TITLE                      \n",
    "YEAR                       \n",
    "IMDB_RATING                \n",
    "IMDB_NUMBEROFVOTES         \n",
    "PLOT                       \n",
    "US_MATURITY_RATING_STRING  \n",
    "US_MATURITY_RATING         \n",
    "GENRES \n",
    "\n",
    "In addition we added two fields that will help us with our fictional use case that are not derived from the  IMDb dataset\n",
    "\n",
    "CREATION_TIMESTAMP         \n",
    "PROMOTION\n",
    "\n",
    "For the purpose of this workshop we will use the IMDb TT ID to provide a common identifier between the interactions data and the content metadata. Movielens provides its own identifier as well as a the IMDb TT ID (without the leading 'tt') in the 'links.csv' file. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note: </b>Your use of IMDb data is for the sole purpose of completing the AWS workshop and/or tutorial. Any use of IMDb data outside of the AWS workshop and/or tutorial requires a data license from IMDb. To obtain a data license, please contact: imdb-licensing-support@imdb.com. You will not (and will not allow a third party to) (i) use IMDb data, or any derivative works thereof, for any purpose; (ii) copy, sublicense, rent, sell, lease or otherwise transfer or distribute IMDb data or any portion thereof to any person or entity for any purpose not permitted within the workshop and/or tutorial; (iii) decompile, disassemble, or otherwise reverse engineer or attempt to reconstruct or discover any source code or underlying ideas or algorithms of IMDb data by any means whatsoever; or (iv) knowingly remove any product identification, copyright or other notices from IMDb data.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note: </b>This dataset is not required for Amazon Personalize to generate recommendations, but providing good item metadata will ensure the best results in your trained models.\n",
    "</div>\n",
    "\n",
    "### Interactions data\n",
    "\n",
    "* Interations data: we use the ml-latest-small dataset from the [Movielens](https://grouplens.org/datasets/movielens/) project as a proxy for user-item interactions. \n",
    "\n",
    "The interaction data consists of information about the interactions the users of the fictional app will have with the content. This usually comes from analytics tools or Customer Data Platform's (CDP). The best interaction data for use for Amazon Personalize would include the sequential order of user behavior, what content was watched/clicked on and the order it was interacted with. To simulate our interaction data, we will be using data from the [MovieLens project](https://grouplens.org/datasets/movielens/). Movielens offers multiple versions of their dataset, for the purposes of this workshop we will be using the reduced version of this dataset (approx 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users).\n",
    "\n",
    "### User data\n",
    "\n",
    "In this example we will not be using user data to train the Amazon Personalize model, because this data is not available from the Movielens dataset we are using. However we will be experimenting with different user personas when working on the email preparation and prompt.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This dataset is not manatory for Amazon Personalize to generate recommendations, but providing good item metadata will ensure the best results in your trained models.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbf885",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the installed packages\n",
    "!pip uninstall -y awscli\n",
    "!pip install awscli\n",
    "!pip uninstall -y boto3 botocore\n",
    "!pip install botocore\n",
    "!pip install boto3\n",
    "!pip uninstall -y numexpr\n",
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import boto3\n",
    "import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f0ece",
   "metadata": {},
   "source": [
    "## Load the variable names\n",
    "We load the variable names from a file. These are shared with the pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('params.json')\n",
    "parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a21f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_dataset_group_name = parameters['datasetGroup']['serviceConfig']['name']\n",
    "\n",
    "interactions_schema_name = parameters['datasets']['interactions']['schema']['serviceConfig']['name']\n",
    "interactions_dataset_name = parameters['datasets']['interactions']['dataset']['serviceConfig']['name']\n",
    "\n",
    "items_schema_name = parameters['datasets']['items']['schema']['serviceConfig']['name']\n",
    "items_dataset_name = parameters['datasets']['items']['dataset']['serviceConfig']['name']\n",
    "\n",
    "#The following job names are the starting Strings of the job names that can be created\n",
    "interactions_import_job_name = 'dataset_import_interaction'\n",
    "items_import_job_name = 'dataset_import_item'\n",
    "# users_import_job_name = 'dataset_import_user'\n",
    "\n",
    "for recommender in parameters['recommenders']:\n",
    "    # This is currently configured assuming only one recommender, if there are multiple\n",
    "    # recommenders of the same type further configuration is needed.\n",
    "    if (recommender['serviceConfig']['recipeArn'] == 'arn:aws:personalize:::recipe/aws-vod-top-picks'):\n",
    "        recommender_top_picks_for_you_name =recommender['serviceConfig']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the directories\n",
    "data_dir = 'poc_data'\n",
    "!mkdir $data_dir\n",
    "imdb_dir = data_dir+'/imdb'\n",
    "!mkdir $imdb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d243f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable names\n",
    "items_filename = \"items.csv\"\n",
    "interactions_filename = \"interactions.csv\"\n",
    "movielens_dataset_dir = data_dir + \"/ml-latest-small/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759e3b2",
   "metadata": {},
   "source": [
    "## Prepare the Item Metadata <a class=\"anchor\" id=\"prepare_items\"></a>\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2347060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download IMDB data\n",
    "!wget -P $imdb_dir https://d2peeor3oplhc6.cloudfront.net/personalize-immersionday-media/imdb/items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883306b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read movielens data\n",
    "item_data = pd.read_csv(data_dir + '/imdb/items.csv', sep=',', dtype={'PROMOTION': \"string\"})\n",
    "item_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a750da",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a33a1c",
   "metadata": {},
   "source": [
    "That's it! At this point the item data is ready to go, and we just need to save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeba982",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data.to_csv((data_dir+\"/\"+items_filename), index=True, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03c782",
   "metadata": {},
   "source": [
    "## Prepare the Interactions data \n",
    "\n",
    "First, you will download the dataset from the [MovieLens project](https://grouplens.org/datasets/movielens/) website and unzip it in a new folder using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbd092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copy movielens data\n",
    "!cd $data_dir && wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!cd $data_dir && unzip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e5cf0",
   "metadata": {},
   "source": [
    "We can look at the README.txt file and licensing, do not skip over usage license!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d497ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize $data_dir/ml-latest-small/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158dd43",
   "metadata": {},
   "source": [
    "The primary data we are interested in for a recommendation use case is the actual interactions that the users had with the titles(items). \n",
    "\n",
    "Open the `ratings.csv` file and take a look at the some rows from throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data = pd.read_csv(movielens_dataset_dir + '/ratings.csv', sep=',', dtype={'userId': \"int64\", 'movieId': \"str\"})\n",
    "interaction_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8591807",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e606235",
   "metadata": {},
   "source": [
    "### Convert the Interactions Data\n",
    "\n",
    "The interaction data generally is acquired from anaytics or CDP platforms that can identify individual interactions with content/items within a platform. \n",
    "\n",
    "We need to do a few things to get this dataset ready to subsitute for our services interaction data.\n",
    "\n",
    "First off, the movieId is a unique identifier provided by Movielens for each title. However as we saw above IMDb has a much richer set of metadata about the content catalog. In order to use the IMDb data we will need to use a common  identifier between our items and our interactions dataset, which is the IMDb imdbId. To do this Movielens provides the 'links.csv' file which helps convert between the two identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(movielens_dataset_dir + '/links.csv', sep=',', usecols=[0,1], encoding='latin-1', dtype={'movieId': \"str\", 'imdbId': \"str\", 'tmdbId': \"str\"})\n",
    "pd.set_option('display.max_rows', 25)\n",
    "links['imdbId'] = 'tt' + links['imdbId'].astype(object)\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a362ec",
   "metadata": {},
   "source": [
    "As you can see this provides a method to identify what the IMDb id is for every title in our interactions dataset, now we will convert the ratings.csv data to utilize the IMDb ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = interaction_data.merge(links, on='movieId')\n",
    "imdb_data.drop(columns='movieId', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa271a2",
   "metadata": {},
   "source": [
    "Now we have a interactions dataset that matches our item catalog dataset. \n",
    "\n",
    "### Simulating an interaction dataset \n",
    "\n",
    "We are going to make one more modification to make the MoviesLens dataset more like the analytics data that a video streaming service would see in their interactions. MoviesLens is an explicit movie rating dataset, which means users are presented a movie and asked to give it a rating. For recommendation systems/personalization, the industry has moved on to using more implicit data. This is due to many reasons including low numbers of customers rating titles and customers tastes changing over time. Some of the benefits of implicit interaction data is that it is the actual behavior of all users and changes over time as their viewing behavior changes.\n",
    "\n",
    "To convert the explicit interaction MovieLens ratings dataset into an implicit dataset we are going to create a synthetic dataset using the ratings in MovieLens. \n",
    "\n",
    "- Implicit interactions are inherently positive interactions so we will be dropping any rating that is below 2 stars. \n",
    "- Ratings of 2 and 3 stars are neutral to slightly positive, we are going to create synthetic \"Click\" events to simulate a viewer clicking on a title in the UnicornFlix app.\n",
    "- Ratings of 4 and 5 are overwhelmingly positive, we will use these to create synthetic \"Watch\" and \"Click\" events to simulate a viewer both clicking on a title and watching at least 80% of a title.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> These interactions will be directionaly accurate, but is not a good substitute for actual temporal based interaction data, the order that viewers rated movies on the MovieLens website is not as good as the order of interactions on an actual Video On Demand Streaming app. For more information about the importance of the temporal interaction data see https://www.amazon.science/publications/temporal-contextual-recommendation-in-real-time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_df = imdb_data.copy()\n",
    "watched_df = watched_df[watched_df['rating'] > 3]\n",
    "watched_df = watched_df[['userId', 'imdbId', 'timestamp']]\n",
    "watched_df['EVENT_TYPE']='Watch'\n",
    "watched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fa2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df = imdb_data.copy()\n",
    "clicked_df = clicked_df[clicked_df['rating'] > 1]\n",
    "clicked_df = clicked_df[['userId', 'imdbId', 'timestamp']]\n",
    "clicked_df['EVENT_TYPE']='Click'\n",
    "clicked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = clicked_df.copy()\n",
    "\n",
    "interactions_df = pd.concat([interactions_df, watched_df])\n",
    "interactions_df.sort_values(\"timestamp\", axis = 0, ascending = True,\n",
    "                 inplace = True, na_position ='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8470e",
   "metadata": {},
   "source": [
    "Lets look at what the new dataset looks like and ensure that the data reflects our fictional streaming services streaming analytics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac31690",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799797c",
   "metadata": {},
   "source": [
    " Amazon Personalize has default column names for users, items, and timestamp. These default column names are `USER_ID`, `ITEM_ID`, `TIMESTAMP` and `EVENT_VALUE` for the [VIDEO_ON_DEMAND domain dataset](https://docs.aws.amazon.com/personalize/latest/dg/VIDEO-ON-DEMAND-datasets-and-schemas.html). The final modification to the dataset is to replace the existing column headers with the default headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.rename(columns = {'userId':'USER_ID', 'imdbId':'ITEM_ID',\n",
    "                              'timestamp':'TIMESTAMP'}, inplace = True)\n",
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2af6e",
   "metadata": {},
   "source": [
    "We'll be using a subset of the IMDB dataset for this workshop that has been cleaned to remove movies that don't have valid values for the metadata we are using in our ITEMs dataset (we'll work with this more in the net section), so we'll need to make sure we don't have any interactions that have IMDb movie ids that are not in our subset of the IMDb data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff428b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(data_dir + '/imdb' + '/items.csv', sep=',', usecols=[0,1], encoding='latin-1', dtype={'movieId': \"str\", 'imdbId': \"str\", 'tmdbId': \"str\"})\n",
    "pd.set_option('display.max_rows', 25)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f80e00",
   "metadata": {},
   "source": [
    "The number of unique ITEM_IDs are not the same in the IMDB data and the interactions data, so we'll clean out the data points with ITEM_IDs that do not have item metadata from the interactions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df.merge(movies, on='ITEM_ID')\n",
    "interactions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97717293",
   "metadata": {},
   "source": [
    "We will also drop the TITLE column as it is not required in the interactions dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f904f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df.drop(columns=['TITLE'])\n",
    "interactions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d4096",
   "metadata": {},
   "source": [
    "That's it! At this point the data is ready to go, and we just need to save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.to_csv((data_dir+\"/\"+interactions_filename), index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c58331",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0ceb",
   "metadata": {},
   "source": [
    "## Prepare the User Metadata <a class=\"anchor\" id=\"prepare_users\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "The dataset does not have any user metadata so we will extract the distinct user_ids in our interactions dataset and experiment with different types of users later in this workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc429383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique user ids from the interaction dataset\n",
    "\n",
    "user_ids = interactions_df['USER_ID'].unique()\n",
    "user_data = pd.DataFrame()\n",
    "user_data[\"USER_ID\"]= user_ids\n",
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862de0fd",
   "metadata": {},
   "source": [
    "Let's see how many users we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd6e13",
   "metadata": {},
   "source": [
    "## Personalize Model\n",
    "\n",
    "In order to get the recommendations, you need to train Amazon Personalized Recommender.\n",
    "\n",
    "In this case we will use the domain optimized Recommender [Top picks for you](https://docs.aws.amazon.com/personalize/latest/dg/VIDEO_ON_DEMAND-use-cases.html#top-picks-use-case): personalized content recommendations for a user that you specify. With this use case, Amazon Personalize automatically filters videos the user watched based on the userId that you specify and Watch events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store interactions_filename\n",
    "%store items_filename\n",
    "%store recommender_top_picks_for_you_name\n",
    "%store workshop_dataset_group_name\n",
    "%store interactions_schema_name\n",
    "%store interactions_dataset_name\n",
    "%store interactions_import_job_name\n",
    "%store items_schema_name\n",
    "%store items_dataset_name\n",
    "%store items_import_job_name\n",
    "%store data_dir\n",
    "%store user_ids\n",
    "%store item_data\n",
    "%store interactions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30f1b4",
   "metadata": {},
   "source": [
    "Go to [02_Train_Personalize_Model_01_Data](02_Train_Personalize_Model_01_Data.ipynb) to continue, and follow the instructions there to upoload your data and train your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e03ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
