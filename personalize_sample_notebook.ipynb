{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Personalize boto3 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "!wget -N https://s3-us-west-2.amazonaws.com/personalize-cli-json-models/personalize.json\n",
    "!wget -N https://s3-us-west-2.amazonaws.com/personalize-cli-json-models/personalize-runtime.json\n",
    "!aws configure add-model --service-model file://`pwd`/personalize.json --service-name personalize\n",
    "!aws configure add-model --service-model file://`pwd`/personalize-runtime.json --service-name personalize-runtime\n",
    "\n",
    "personalize = boto3.client(service_name='personalize', endpoint_url='https://personalize.us-east-1.amazonaws.com')\n",
    "personalize_runtime = boto3.client(service_name='personalize-runtime', endpoint_url='https://personalize-runtime.us-east-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify a Bucket and Data Output Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"personalize-demo\"           # replace with the name of your S3 bucket\n",
    "filename = \"DEMO-movie-lens-100k.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, Prepare, and Upload Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       USER_ID  ITEM_ID  RATING  TIMESTAMP\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "...        ...      ...     ...        ...\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['RATING'] > 3.6]                # keep only movies rated 3.6 and above\n",
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "data.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:us-east-1:237539672711:schema/DEMO-schema\", \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"12eb7cba-2b64-4be9-9f6e-eeebff7629a5\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 05:49:04 GMT\", \n",
      "      \"x-amzn-requestid\": \"12eb7cba-2b64-4be9-9f6e-eeebff7629a5\", \n",
      "      \"content-length\": \"79\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"DEMO-schema\",\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print json.dumps(create_schema_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Dataset Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-1:237539672711:dataset-group/DEMO-dataset-group\", \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"d6b600c8-6168-4fcf-b7bf-97bd16a79aba\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 05:49:08 GMT\", \n",
      "      \"x-amzn-requestid\": \"d6b600c8-6168-4fcf-b7bf-97bd16a79aba\", \n",
      "      \"content-length\": \"99\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"DEMO-dataset-group\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print json.dumps(create_dataset_group_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Group to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print \"DatasetGroup: {}\".format(status)\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"29ab75c8-df6e-4807-943f-1b48014181d1\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 05:50:19 GMT\", \n",
      "      \"x-amzn-requestid\": \"29ab75c8-df6e-4807-943f-1b48014181d1\", \n",
      "      \"content-length\": \"101\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }, \n",
      "  \"datasetArn\": \"arn:aws:personalize:us-east-1:237539672711:dataset/DEMO-dataset-group/INTERACTIONS\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn\n",
    ")\n",
    "\n",
    "dataset_arn = create_dataset_response['datasetArn']\n",
    "print json.dumps(create_dataset_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare, Create, and Wait for Dataset Import Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach policy to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create S3 Read Only Access Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::237539672711:role/PersonalizeS3Role\n"
     ]
    }
   ],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeS3Role\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ");\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    ");\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:237539672711:dataset-import-job/DEMO-dataset-import-job\", \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"3c77fe8d-d9fe-4ca5-ad03-b18e937acbb3\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 05:50:55 GMT\", \n",
      "      \"x-amzn-requestid\": \"3c77fe8d-d9fe-4ca5-ad03-b18e937acbb3\", \n",
      "      \"content-length\": \"113\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"DEMO-dataset-import-job\",\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print json.dumps(create_dataset_import_job_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Import Job and Dataset Import Job Run to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetImportJob: CREATE PENDING\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: CREATE IN_PROGRESS\n",
      "LatestDatasetImportJobRun: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print \"DatasetImportJob: {}\".format(status)\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print \"LatestDatasetImportJobRun: {}\".format(status)\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:personalize:::recipe/awspersonalizehrnnmodel\n"
     ]
    }
   ],
   "source": [
    "recipe_list = [\n",
    "    \"arn:aws:personalize:::recipe/awspersonalizehrnnmodel\",\n",
    "    \"arn:aws:personalize:::recipe/awspersonalizedeepfmmodel\",\n",
    "    \"arn:aws:personalize:::recipe/awspersonalizesimsmodel\",\n",
    "    \"arn:aws:personalize:::recipe/awspersonalizeffnnmodel\",\n",
    "    \"arn:aws:personalize:::recipe/popularity-baseline\"\n",
    "]\n",
    "\n",
    "recipe_arn = recipe_list[0]\n",
    "print recipe_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:237539672711:solution/DEMO-solution\", \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"2042832f-0775-43e2-86de-53a061be1f63\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Mon, 03 Dec 2018 23:55:17 GMT\", \n",
      "      \"x-amzn-requestid\": \"2042832f-0775-43e2-86de-53a061be1f63\", \n",
      "      \"content-length\": \"83\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"DEMO-solution\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print json.dumps(create_solution_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Solution to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: CREATE PENDING\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: CREATE IN_PROGRESS\n",
      "Solution: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_response = personalize.describe_solution(\n",
    "        solutionArn = solution_arn\n",
    "    )\n",
    "    status = describe_solution_response[\"solution\"][\"status\"]\n",
    "    print \"Solution: {}\".format(status)\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Metrics of Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metrics\": {\n",
      "    \"arn:aws:personalize:us-east-1:237539672711:model/awspersonalizehrnnmodel-c2f6287c\": {\n",
      "      \"_user_history_length_10_pct_quantile\": 11.0, \n",
      "      \"_user_history_length_mean\": 54.34065934065934, \n",
      "      \"normalized_discounted_cumulative_gain_at_10\": 0.027472527472527472, \n",
      "      \"_num_unique_items\": 1077.0, \n",
      "      \"normalized_discounted_cumulative_gain_at_5\": 0.016483516483516484, \n",
      "      \"_user_history_length_50_pct_quantile\": 40.0, \n",
      "      \"precision_at_10\": 0.005494505494505495, \n",
      "      \"mean_reciprocal_rank\": 0.019587187573612913, \n",
      "      \"coverage\": 0.4159702878365831, \n",
      "      \"precision_at_25\": 0.006593406593406594, \n",
      "      \"precision_at_5\": 0.004395604395604396, \n",
      "      \"normalized_discounted_cumulative_gain_at_25\": 0.055378468279180526, \n",
      "      \"_user_history_length_90_pct_quantile\": 120.0, \n",
      "      \"_num_evaluation_users\": 91.0\n",
      "    }\n",
      "  }, \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"5b5f4f4f-5249-4c0e-9f83-45e3fe22f09f\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 00:53:54 GMT\", \n",
      "      \"x-amzn-requestid\": \"5b5f4f4f-5249-4c0e-9f83-45e3fe22f09f\", \n",
      "      \"content-length\": \"724\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_metrics_response = personalize.get_metrics(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "print json.dumps(get_metrics_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:237539672711:campaign/DEMO-campaign\", \n",
      "  \"ResponseMetadata\": {\n",
      "    \"RetryAttempts\": 0, \n",
      "    \"HTTPStatusCode\": 200, \n",
      "    \"RequestId\": \"527e97ba-683c-4dc7-8218-00716f22c904\", \n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 04 Dec 2018 00:54:17 GMT\", \n",
      "      \"x-amzn-requestid\": \"527e97ba-683c-4dc7-8218-00716f22c904\", \n",
      "      \"content-length\": \"83\", \n",
      "      \"content-type\": \"application/x-amz-json-1.1\", \n",
      "      \"connection\": \"keep-alive\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"DEMO-campaign\",\n",
    "    solutionArn = solution_arn,\n",
    "    updateMode = \"MANUAL\"\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print json.dumps(create_campaign_response, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Campaign to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign: CREATE PENDING\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print \"Campaign: {}\".format(status)\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a User and an Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: 711\n",
      "ITEM: Silence of the Lambs, The (1991)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ITEM_ID                                      TITLE\n",
       "0           1                           Toy Story (1995)\n",
       "1           2                           GoldenEye (1995)\n",
       "...       ...                                        ...\n",
       "1680     1681                        You So Crazy (1994)\n",
       "1681     1682  Scream of Stone (Schrei aus Stein) (1991)\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], header=None)\n",
    "items.columns = ['ITEM_ID', 'TITLE']\n",
    "\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "item_title = items.loc[items['ITEM_ID'] == item_id].values[0][-1]\n",
    "print \"USER: {}\".format(user_id)\n",
    "print \"ITEM: {}\".format(item_title)\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GetRecommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [\n",
      "  \"Godfather, The (1972)\", \n",
      "  \"Contact (1997)\", \n",
      "  \"Titanic (1997)\", \n",
      "  \"Star Wars (1977)\", \n",
      "  \"Fargo (1996)\", \n",
      "  \"Liar Liar (1997)\", \n",
      "  \"Evita (1996)\", \n",
      "  \"Jerry Maguire (1996)\", \n",
      "  \"Scream (1996)\", \n",
      "  \"Devil's Advocate, The (1997)\", \n",
      "  \"Full Monty, The (1997)\", \n",
      "  \"Conspiracy Theory (1997)\", \n",
      "  \"Edge, The (1997)\", \n",
      "  \"Sense and Sensibility (1995)\", \n",
      "  \"English Patient, The (1996)\", \n",
      "  \"Twelve Monkeys (1995)\", \n",
      "  \"L.A. Confidential (1997)\", \n",
      "  \"As Good As It Gets (1997)\", \n",
      "  \"In & Out (1997)\", \n",
      "  \"Rock, The (1996)\", \n",
      "  \"Return of the Jedi (1983)\", \n",
      "  \"Amistad (1997)\", \n",
      "  \"Men in Black (1997)\", \n",
      "  \"Truth About Cats & Dogs, The (1996)\", \n",
      "  \"Alien: Resurrection (1997)\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    itemId = str(item_id)\n",
    ")\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "title_list = [items.loc[items['ITEM_ID'] == np.int(item['itemId'])].values[0][-1] for item in item_list]\n",
    "\n",
    "print \"Recommendations: {}\".format(json.dumps(title_list, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
